{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2eb69080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. ë°ì´í„° ë¡œë“œ\n",
    "merged = pd.read_csv(\"analysis_results/1ì‹œê°„ ë‹¨ìœ„ ë°ì´í„° ë¶„ì„/merged_hourly_long_utf8sig.csv\")\n",
    "metrics = pd.read_csv(\"analysis_results/1ì‹œê°„ ë‹¨ìœ„ ë°ì´í„° ë¶„ì„/metrics_train.csv\")\n",
    "submission_sample = pd.read_csv(\"analysis_results/1ì‹œê°„ ë‹¨ìœ„ ë°ì´í„° ë¶„ì„/submission_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f26a6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. ë‚ ì§œ ì •ë¦¬\n",
    "merged['date'] = pd.to_datetime(merged['date']).dt.date\n",
    "metrics['lifelog_date'] = pd.to_datetime(metrics['lifelog_date']).dt.date\n",
    "submission_sample['lifelog_date'] = pd.to_datetime(submission_sample['lifelog_date']).dt.date\n",
    "\n",
    "# 3. í•™ìŠµ ë°ì´í„° ë³‘í•©\n",
    "train_df = pd.merge(merged, metrics, left_on=['subject_id', 'date'], right_on=['subject_id', 'lifelog_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccc046ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4282, number of negative: 4358\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001671 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10653\n",
      "[LightGBM] [Info] Number of data points in the train set: 8640, number of used features: 60\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495602 -> initscore=-0.017593\n",
      "[LightGBM] [Info] Start training from score -0.017593\n",
      "ğŸ“Š í‰ê°€ ê²°ê³¼\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.81      0.67      1090\n",
      "           1       0.67      0.38      0.48      1070\n",
      "\n",
      "    accuracy                           0.60      2160\n",
      "   macro avg       0.62      0.60      0.58      2160\n",
      "weighted avg       0.62      0.60      0.58      2160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "# 4. í”¼ì²˜/íƒ€ê²Ÿ ë¶„ë¦¬\n",
    "target = 'Q1'\n",
    "drop_cols = ['subject_id', 'date', 'lifelog_date', 'sleep_date', 'Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']\n",
    "\n",
    "X = train_df.drop(columns=drop_cols)\n",
    "y = train_df[target]\n",
    "\n",
    "# 5. ê²°ì¸¡ì¹˜ ì²˜ë¦¬\n",
    "X.fillna(0, inplace=True)\n",
    "\n",
    "# 6. ë¬¸ìì—´ ë° í•œê¸€ í”¼ì²˜ ì œê±°\n",
    "X = X.select_dtypes(include=['number'])\n",
    "X = X.loc[:, ~X.columns.str.contains('[ê°€-í£]', regex=True)]\n",
    "\n",
    "# 7. íŠ¹ìˆ˜ë¬¸ì ì„¸ì²™ í•¨ìˆ˜\n",
    "def sanitize_column_names(df):\n",
    "    df.columns = (\n",
    "        df.columns\n",
    "        .str.replace(r\"[^\\w]\", \"_\", regex=True)\n",
    "        .str.replace(r\"__+\", \"_\", regex=True)\n",
    "        .str.strip(\"_\")\n",
    "    )\n",
    "    return df\n",
    "\n",
    "X = sanitize_column_names(X)\n",
    "\n",
    "# 8. í•™ìŠµ/ê²€ì¦ ë¶„ë¦¬\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "X_train = X.loc[X_train.index]\n",
    "X_val = X.loc[X_val.index]\n",
    "\n",
    "# 9. ëª¨ë¸ í•™ìŠµ\n",
    "model = LGBMClassifier(n_estimators=500, learning_rate=0.03, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"ğŸ“Š í‰ê°€ ê²°ê³¼\")\n",
    "print(classification_report(y_val, model.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0352e8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“… ë³‘í•© ê°€ëŠ¥í•œ ë‚ ì§œ ìˆ˜: 104\n",
      "ì˜ˆì‹œ: ['2024-07-23', '2024-08-16', '2024-09-21', '2024-08-31', '2024-08-29']\n"
     ]
    }
   ],
   "source": [
    "merged_dates = set(merged['date'].astype(str).unique())\n",
    "submission_dates = set(submission_sample['lifelog_date'].astype(str).unique())\n",
    "common_dates = merged_dates & submission_dates\n",
    "\n",
    "print(\"ğŸ“… ë³‘í•© ê°€ëŠ¥í•œ ë‚ ì§œ ìˆ˜:\", len(common_dates))\n",
    "print(\"ì˜ˆì‹œ:\", list(common_dates)[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbbaf13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged subject_ids: ['id01' 'id02' 'id03' 'id04' 'id05']\n",
      "submission_sample subject_ids: ['id01' 'id02' 'id03' 'id04' 'id05']\n",
      "ğŸ” ë³‘í•© ê°€ëŠ¥í•œ (subject_id, date) ìŒ ê°œìˆ˜: 0\n",
      "ì˜ˆì‹œ: []\n",
      "âœ… test_df shape after fixed merge: (0, 63)\n",
      "âœ… test_X shape: (0, 63)\n",
      "âœ… test_X columns same as X: []\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input data must be 2 dimensional and non empty.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     38\u001b[39m test_X = test_df.copy()\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# ì˜ˆì¸¡ ìˆ˜í–‰\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m test_df[target] = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# 12. ì œì¶œ íŒŒì¼ ìƒì„±\u001b[39;00m\n\u001b[32m     44\u001b[39m submission = submission_sample[[\u001b[33m'\u001b[39m\u001b[33msubject_id\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlifelog_date\u001b[39m\u001b[33m'\u001b[39m]].copy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\lightgbm\\sklearn.py:1597\u001b[39m, in \u001b[36mLGBMClassifier.predict\u001b[39m\u001b[34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[39m\n\u001b[32m   1585\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\n\u001b[32m   1586\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1587\u001b[39m     X: _LGBM_ScikitMatrixLike,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1594\u001b[39m     **kwargs: Any,\n\u001b[32m   1595\u001b[39m ):\n\u001b[32m   1596\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1597\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1598\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1599\u001b[39m \u001b[43m        \u001b[49m\u001b[43mraw_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraw_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1600\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1602\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpred_leaf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpred_leaf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1603\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpred_contrib\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpred_contrib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1604\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1605\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1606\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1607\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m._objective) \u001b[38;5;129;01mor\u001b[39;00m raw_score \u001b[38;5;129;01mor\u001b[39;00m pred_leaf \u001b[38;5;129;01mor\u001b[39;00m pred_contrib:\n\u001b[32m   1608\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\lightgbm\\sklearn.py:1627\u001b[39m, in \u001b[36mLGBMClassifier.predict_proba\u001b[39m\u001b[34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[39m\n\u001b[32m   1615\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict_proba\u001b[39m(\n\u001b[32m   1616\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1617\u001b[39m     X: _LGBM_ScikitMatrixLike,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1624\u001b[39m     **kwargs: Any,\n\u001b[32m   1625\u001b[39m ):\n\u001b[32m   1626\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Docstring is set after definition, using a template.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1627\u001b[39m     result = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1628\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mraw_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraw_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1631\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1632\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpred_leaf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpred_leaf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1633\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpred_contrib\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpred_contrib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1634\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1635\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1636\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1637\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m._objective) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (raw_score \u001b[38;5;129;01mor\u001b[39;00m pred_leaf \u001b[38;5;129;01mor\u001b[39;00m pred_contrib):\n\u001b[32m   1638\u001b[39m         _log_warning(\n\u001b[32m   1639\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mCannot compute class probabilities or labels \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1640\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mdue to the usage of customized objective function.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1641\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mReturning raw scores instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1642\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\lightgbm\\sklearn.py:1144\u001b[39m, in \u001b[36mLGBMModel.predict\u001b[39m\u001b[34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[39m\n\u001b[32m   1141\u001b[39m predict_params = _choose_param_value(\u001b[33m\"\u001b[39m\u001b[33mnum_threads\u001b[39m\u001b[33m\"\u001b[39m, predict_params, \u001b[38;5;28mself\u001b[39m.n_jobs)\n\u001b[32m   1142\u001b[39m predict_params[\u001b[33m\"\u001b[39m\u001b[33mnum_threads\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m._process_n_jobs(predict_params[\u001b[33m\"\u001b[39m\u001b[33mnum_threads\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m1144\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_Booster\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[union-attr]\u001b[39;49;00m\n\u001b[32m   1145\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1146\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraw_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraw_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1147\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpred_leaf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpred_leaf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpred_contrib\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpred_contrib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpredict_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\lightgbm\\basic.py:4767\u001b[39m, in \u001b[36mBooster.predict\u001b[39m\u001b[34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, validate_features, **kwargs)\u001b[39m\n\u001b[32m   4765\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4766\u001b[39m         num_iteration = -\u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m4767\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpredictor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4768\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4769\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4770\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4771\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraw_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraw_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4772\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpred_leaf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpred_leaf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4773\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpred_contrib\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpred_contrib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4774\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_has_header\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_has_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4775\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4776\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\lightgbm\\basic.py:1158\u001b[39m, in \u001b[36m_InnerPredictor.predict\u001b[39m\u001b[34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, validate_features)\u001b[39m\n\u001b[32m   1149\u001b[39m     _safe_call(\n\u001b[32m   1150\u001b[39m         _LIB.LGBM_BoosterValidateFeatureNames(\n\u001b[32m   1151\u001b[39m             \u001b[38;5;28mself\u001b[39m._handle,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1154\u001b[39m         )\n\u001b[32m   1155\u001b[39m     )\n\u001b[32m   1157\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd_DataFrame):\n\u001b[32m-> \u001b[39m\u001b[32m1158\u001b[39m     data = \u001b[43m_data_from_pandas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpandas_categorical\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpandas_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m   1165\u001b[39m predict_type = _C_API_PREDICT_NORMAL\n\u001b[32m   1166\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m raw_score:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\lightgbm\\basic.py:834\u001b[39m, in \u001b[36m_data_from_pandas\u001b[39m\u001b[34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[39m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_data_from_pandas\u001b[39m(\n\u001b[32m    828\u001b[39m     data: pd_DataFrame,\n\u001b[32m    829\u001b[39m     feature_name: _LGBM_FeatureNameConfiguration,\n\u001b[32m    830\u001b[39m     categorical_feature: _LGBM_CategoricalFeatureConfiguration,\n\u001b[32m    831\u001b[39m     pandas_categorical: Optional[List[List]],\n\u001b[32m    832\u001b[39m ) -> Tuple[np.ndarray, List[\u001b[38;5;28mstr\u001b[39m], Union[List[\u001b[38;5;28mstr\u001b[39m], List[\u001b[38;5;28mint\u001b[39m]], List[List]]:\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data.shape) != \u001b[32m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m data.shape[\u001b[32m0\u001b[39m] < \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m834\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mInput data must be 2 dimensional and non empty.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    836\u001b[39m     \u001b[38;5;66;03m# take shallow copy in case we modify categorical columns\u001b[39;00m\n\u001b[32m    837\u001b[39m     \u001b[38;5;66;03m# whole column modifications don't change the original df\u001b[39;00m\n\u001b[32m    838\u001b[39m     data = data.copy(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mValueError\u001b[39m: Input data must be 2 dimensional and non empty."
     ]
    }
   ],
   "source": [
    "# ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "merged['date_str'] = pd.to_datetime(merged['date']).astype(str)\n",
    "submission_sample['lifelog_date_str'] = pd.to_datetime(submission_sample['lifelog_date']).astype(str)\n",
    "\n",
    "# ë³‘í•© ê°€ëŠ¥í•œ key ì§ì ‘ ì¶”ì¶œ\n",
    "merged_keys = set(zip(merged['subject_id'], merged['date_str']))\n",
    "submission_keys = set(zip(submission_sample['subject_id'], submission_sample['lifelog_date_str']))\n",
    "\n",
    "common_keys = merged_keys & submission_keys\n",
    "\n",
    "print(\"merged subject_ids:\", merged['subject_id'].unique()[:5])\n",
    "print(\"submission_sample subject_ids:\", submission_sample['subject_id'].unique()[:5])\n",
    "\n",
    "print(\"ğŸ” ë³‘í•© ê°€ëŠ¥í•œ (subject_id, date) ìŒ ê°œìˆ˜:\", len(common_keys))\n",
    "print(\"ì˜ˆì‹œ:\", list(common_keys)[:5])\n",
    "\n",
    "print(\"âœ… test_df shape after fixed merge:\", test_df.shape)\n",
    "print(\"âœ… test_X shape:\", test_X.shape)\n",
    "print(\"âœ… test_X columns same as X:\", list(set(X.columns) - set(test_X.columns)))\n",
    "\n",
    "\n",
    "# 1. test_dfì—ì„œ ìˆ«ìí˜• í”¼ì²˜ë§Œ ì„ íƒ\n",
    "test_df = test_df.select_dtypes(include=['number'])\n",
    "\n",
    "# 2. í•œê¸€ ì»¬ëŸ¼ ì œê±°\n",
    "test_df = test_df.loc[:, ~test_df.columns.str.contains('[ê°€-í£]', regex=True)]\n",
    "\n",
    "# 3. íŠ¹ìˆ˜ë¬¸ì ì œê±°\n",
    "test_df = sanitize_column_names(test_df)\n",
    "\n",
    "# 4. ëˆ„ë½ëœ ì»¬ëŸ¼ ì¶”ê°€\n",
    "missing_cols = set(X.columns) - set(test_df.columns)\n",
    "for col in missing_cols:\n",
    "    test_df[col] = 0\n",
    "\n",
    "# 5. ìˆœì„œ ì •ë ¬\n",
    "test_df = test_df[X.columns]\n",
    "test_X = test_df.copy()\n",
    "\n",
    "# ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "test_df[target] = model.predict(test_X)\n",
    "\n",
    "# 12. ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "submission = submission_sample[['subject_id', 'lifelog_date']].copy()\n",
    "submission[target] = test_df[target].values\n",
    "\n",
    "# 13. ì €ì¥\n",
    "submission.to_csv(f\"submission_{target}.csv\", index=False, encoding='utf-8-sig')\n",
    "print(f\"âœ… ì €ì¥ ì™„ë£Œ: submission_{target}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
