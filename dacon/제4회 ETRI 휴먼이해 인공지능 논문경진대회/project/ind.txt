project/
│
├── /data/                  # 실제 데이터 파일 위치 (예: train.csv, test.csv 등)
├── /models/                # 저장된 모델 가중치 파일 (선택적)
├── /notebooks/
│   └── main.ipynb          # 실행 가능한 주 분석 및 모델링 노트북
├── /src/
│   └── model.py            # 모델 정의 코드 (함수 or 클래스)
│   └── utils.py            # 데이터 전처리, 시각화 등 유틸 함수
├── requirements.txt        # 필요 라이브러리 명시
├── environment.txt         # OS 및 라이브러리 버전 포함
├── README.md               # 프로젝트 설명서
└── model_description.txt   # 모델 구조 및 특징 정리 (자유 양식)

모든 값은 범주형 클래스 집합 --- 분류 문제
| 타깃 컬럼 | 값       | 예측 타입     | 설명             |
| ----- | ------- | --------- | -------------- |
| `Q1`  | 0 or 1  | 이진 분류     | 수면의 질 (좋다/나쁘다) |
| `Q2`  | 0 or 1  | 이진 분류     | 피로도 (높다/낮다)    |
| `Q3`  | 0 or 1  | 이진 분류     | 스트레스 (있다/없다)   |
| `S1`  | 0, 1, 2 | 다중 클래스 분류 | 총 수면시간 등급      |
| `S2`  | 0 or 1  | 이진 분류     | 수면 효율 (좋다/나쁘다) |
| `S3`  | 0 or 1  | 이진 분류     | 수면 지연 있음/없음    |


앞으로 해야 될 것
1. 데이터 전처리 ( 하루 기준 )
ch2025_mACStatus.parquet  ch2025_mGps.parquet		ch2025_mWifi.parquet
ch2025_mActivity.parquet  ch2025_mLight.parquet		ch2025_wHr.parquet
ch2025_mAmbience.parquet  ch2025_mScreenStatus.parquet	ch2025_wLight.parquet
ch2025_mBle.parquet	  ch2025_mUsageStats.parquet	ch2025_wPedo.parquet
-----
1. 데이터 확인
2. 목표 확인 -- 성공률 예측
3. 결측치 확인 및 처리
4. EDA (시각화 포함한 탐색적 분석)
5. 컬럼별 분석 + 이상치 탐색
6. 데이터 라벨링 및 불리언화
7. 필요없는 컬럼 제거
8. Feature Engineering (파생변수 생성)
9. Feature Importance / 상관 분석
10. 검증 전략 설정 (KFold 등)
11. 모델 선택 및 학습
12. 하이퍼파라미터 튜닝
13. 최종 모델 선정
14. 결과 예측 및 저장
15. 평가 지표 확인 및 대회 제출
--
너무 좋습니다. 센서 데이터는 원래 시계열이지만,
→ 머신러닝에 넣기 위해선 보통 "하루 단위로 요약"합니다.

이미 예시가 준비된 센서:
mACStatus → 충전 비율, 충전 지속 시간 등

mActivity → 활동 비율, 대표 활동 등

다음으로 준비하면 좋을 센서들:
센서 이름	요약 피처 예시
wHr (심박수)	평균/최대/최소/표준편차, 심박 상승 횟수
wPedo (걸음 수)	총 걸음 수, 활동 시간대, 밤 시간대 걸음 수
mLight / wLight (조도)	평균 밝기, 수면 직전 조도 변화량
mScreenStatus	화면 켜짐 횟수, 총 사용 시간, 밤 시간대 사용 여부
mUsageStats	앱 사용 총 시간, 상위 앱 사용 비율 등


📈 점수 향상을 위한 구체적 전략
✅ 1. Feature Engineering 보강
현재 센서들은 잘 요약되었지만:

시간대별 요약을 더 세분화 (예: 2시간 단위)

파생 피처 추가: 심박 변화량, 걸음의 패턴성, 야간 스크린 사용시간 등

wHr, mLight, wLight → 밤 시간대 기준 피처 강조

✅ 2. 모델 개선 및 앙상블
현재는 단일 LightGBM 모델로 각 타깃 예측

대안:

각 타깃마다 별도 최적 모델 선택 (예: Q1~Q3은 XGBoost, S1은 CatBoost)

Soft voting ensemble: 여러 모델의 예측 평균

✅ 3. 하이퍼파라미터 튜닝
현재 공통 파라미터로 학습 중

Optuna, GridSearchCV 등으로 각 타깃별로 튜닝 추천

특히 max_depth, min_child_samples, num_leaves 튜닝이 중요

✅ 4. 정규화된 결측치 처리
fillna(0) → 위험한 경우 있음 (0이 실제 의미 있는 수치일 수 있음)

대안:

fillna(X.mean())

혹은 별도 is_na 플래그 컬럼 추가

✅ 5. Cross Validation 도입
현재는 full train → predict 방식

→ StratifiedKFold로 cross-validation 적용 시 일반화 성능 향상 가능

✅ 6. Feature Selection / Importance 기반 필터링
전체 120여 개 피처 중 중요도가 거의 0인 피처 제거

중요도 높은 상위 50~80개만 학습에 사용해 성능 향상 가능

✳️ 요약: 점수 향상 핵심 정리
구분	추천 작업
✅ 데이터	시간대 세분화, 파생 피처 추가
✅ 모델	CatBoost/XGBoost 교체 or 앙상블
✅ 파라미터	max_depth, num_leaves 등 개별 최적화
✅ 평가	교차검증 기반 성능 확인
✅ 예측결합	다중모델 soft voting ensemble

🔜 다음 단계 추천
가장 빠른 효과 → Feature Importance 기반 Top N 피처만 추려서 재학습

장기적인 성능 향상 → Optuna + KFold 조합

원하시면 바로 그중 하나를 골라 이어서 도와드릴 수 있어요.
예: “Feature Importance 기반 피처 선택 학습”부터 해볼까요?