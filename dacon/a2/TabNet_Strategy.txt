TabNet(Tabular Data : 표형데이터)
표데이터를 위한 딥러닝 모델 
- Feature 선택  자동화 ( 모델이 중요한 feature 골라 씀 )
- Sparse Attention ( 매 순간 일부 feature만 선택적으로 집중 )
- End to End 학습 ( Feature engineering 별로안해도됨 )
- 해석 가능성 ( 어떤 feature에 집중했는지 )
- Pretraining 기능 ( 비지도 학습, 지도학습 가능 )
- +대회에서는 LightGBM + TabNet 앙상블하는 경우도 많다

1. Feature Engineering (최고 중요)
TabNet은 raw feature 잘 받아들이지만,

"투자대비매출", "연도 → 나이로 변환" 같은 가공하면 성능 급상승

log 변환, 비율, 제곱, 루트... 전처리를 다양하게 해보자

"TabNet도 결국 Garbage In → Garbage Out이다."
(데이터가 좋아야 성능이 좋다.)

2. cat_idxs, cat_dims 설정
범주형 feature는 cat_idxs, cat_dims을 정확히 줘야

내부에서 embedding layer를 제대로 만든다

잘못 설정하면 성능 엄청 떨어진다 (silent error 남)

✅ (지금까지 네가 한 세팅, cat_dims 수정한 거 아주 좋았어!)

3. Pretraining → Fine-tuning
Pretraining: Label 없이 "구조"만 먼저 학습 (비지도)

Fine-tuning: 실제 y값 가지고 학습 (지도학습)

데이터가 적거나 noise 많을 때 효과 좋음

(지금 했던 TabNetPretrainer → TabNetRegressor 방식)

4. n_d, n_a, n_steps 튜닝
n_d: decision layer 크기 (보통 32~128)

n_a: attention layer 크기 (보통 32~128)

n_steps: 단계 몇번 밟을지 (3~8)

✅ 기본: (n_d=64, n_a=64, n_steps=5)

→ n_d, n_a 키우면 capacity 커져서 성능 좋아지지만
overfitting 주의해야 함.

5. Learning Rate
TabNet은 학습 민감하다

추천: AdamW(lr=0.005) 또는 Adam(lr=0.001)

learning rate scheduler 쓰면 더 좋음

(초반에 1e-2로 시작했다가 1e-4로 줄이기)

6. Early Stopping
patience=10~20

Validation MAE가 좋아지지 않으면 멈추기

과적합 막고, 학습시간 단축 가능

7. 여러 seed로 앙상블
42, 2024, 777 이런 random_state로 여러 모델 학습

예측을 평균 내기

Noise 줄이면서 성능 확 올라감

(상위권 대회팀은 앙상블 안 하는 경우 거의 없음.)

8. Feature Importance 분석
TabNet은 explainer.fit() 돌리면

각 feature별 중요도(importance)를 시각화할 수 있어

Feature 추가할수록 점수는 내려간다

n_d, n_a 키우면 모델 성능 좋아지지만 학습 느려진다

Pretraining은 데이터 적으면 매우 좋고, 많으면 그냥 Fine-tuning만 해도 된다

learning rate 너무 크면 collapse 난다 (확 튀면서 망함)

이거 보고 불필요한 feature 버리거나 새로운 feature 추가 가능

(✅ TabNet이 XGBoost처럼 "해석 가능한" 딥러닝이라는게 포인트)