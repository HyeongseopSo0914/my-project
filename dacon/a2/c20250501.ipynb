{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d541dac",
   "metadata": {},
   "source": [
    "data load, preprocess, import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e22804e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ë°ì´í„° ë¡œë”©\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# ID ì œê±°\n",
    "train.drop(columns=['ID'], inplace=True)\n",
    "test.drop(columns=['ID'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93274781",
   "metadata": {},
   "source": [
    "ê²°ì¸¡ ì²˜ë¦¬ ë° ì¸ì½”ë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "104951a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ì„¤ë¦½ì—°ë„              0\n",
       "êµ­ê°€                0\n",
       "ë¶„ì•¼                0\n",
       "íˆ¬ìë‹¨ê³„              0\n",
       "ì§ì› ìˆ˜              0\n",
       "ì¸ìˆ˜ì—¬ë¶€              0\n",
       "ìƒì¥ì—¬ë¶€              0\n",
       "ê³ ê°ìˆ˜(ë°±ë§Œëª…)          0\n",
       "ì´ íˆ¬ìê¸ˆ(ì–µì›)         0\n",
       "ì—°ë§¤ì¶œ(ì–µì›)           0\n",
       "SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)    0\n",
       "ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)         0\n",
       "ì§ì› ìˆ˜_ê²°ì¸¡           0\n",
       "ê³ ê°ìˆ˜(ë°±ë§Œëª…)_ê²°ì¸¡       0\n",
       "ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)_ê²°ì¸¡      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›) ìˆ«ìí™”\n",
    "# ê¸°ì—…ê°€ì¹˜ ì»¬ëŸ¼ë„ ë²”ìœ„ ë¬¸ìì—´ ì²˜ë¦¬ ì¶”ê°€\n",
    "\n",
    "def convert_range_to_float(value):\n",
    "    if isinstance(value, str) and '-' in value:\n",
    "        try:\n",
    "            low, high = map(float, value.split('-'))\n",
    "            return (low + high) / 2\n",
    "        except:\n",
    "            return np.nan\n",
    "    try:\n",
    "        return float(value)\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "def encode_categoricals(df, cols):\n",
    "    df = df.copy()\n",
    "    for col in cols:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "    return df\n",
    "\n",
    "def fill_missing_values_v3(df, is_train=True):\n",
    "    df = df.copy()\n",
    "\n",
    "    # ë²”ìœ„ ë¬¸ìì—´ â†’ í‰ê·  ìˆ«ì ì²˜ë¦¬\n",
    "    for col in ['ì—°ë§¤ì¶œ(ì–µì›)', 'ì´ íˆ¬ìê¸ˆ(ì–µì›)', 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)']:\n",
    "        df[col] = df[col].apply(convert_range_to_float)\n",
    "\n",
    "    # ë¶„ì•¼ ê²°ì¸¡ ë° ì¸ì½”ë”©\n",
    "    if 'ë¶„ì•¼' in df.columns:\n",
    "        df['ë¶„ì•¼'] = df['ë¶„ì•¼'].fillna('Unknown')\n",
    "        df['ë¶„ì•¼'] = LabelEncoder().fit_transform(df['ë¶„ì•¼'])\n",
    "\n",
    "    # êµ­ê°€, íˆ¬ìë‹¨ê³„ ì¸ì½”ë”©\n",
    "    df = encode_categoricals(df, ['êµ­ê°€', 'íˆ¬ìë‹¨ê³„'])\n",
    "\n",
    "    # âœ… ê²°ì¸¡ í”Œë˜ê·¸ ì¶”ê°€ í•¨ìˆ˜\n",
    "    def add_missing_flag(column):\n",
    "        flag_col = f'{column}_ê²°ì¸¡'\n",
    "        df[flag_col] = df[column].isnull().astype(int)\n",
    "\n",
    "    # âœ… í”¼ì²˜ì…‹ ìƒì„± í•¨ìˆ˜\n",
    "    def get_features(base):\n",
    "        return base + (['ì„±ê³µí™•ë¥ '] if is_train else [])\n",
    "\n",
    "    # 1. ì§ì› ìˆ˜\n",
    "    if 'ì§ì› ìˆ˜' in df.columns:\n",
    "        add_missing_flag('ì§ì› ìˆ˜')\n",
    "        features = get_features(['ì„¤ë¦½ì—°ë„', 'êµ­ê°€', 'íˆ¬ìë‹¨ê³„', 'ì—°ë§¤ì¶œ(ì–µì›)', 'ì´ íˆ¬ìê¸ˆ(ì–µì›)', 'SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)'])\n",
    "        complete = df[df['ì§ì› ìˆ˜'].notnull()]\n",
    "        missing = df[df['ì§ì› ìˆ˜'].isnull()]\n",
    "        if not complete.empty and not missing.empty:\n",
    "            model = GradientBoostingRegressor()\n",
    "            model.fit(complete[features], complete['ì§ì› ìˆ˜'])\n",
    "            df.loc[df['ì§ì› ìˆ˜'].isnull(), 'ì§ì› ìˆ˜'] = model.predict(missing[features])\n",
    "\n",
    "    # 2. ê³ ê° ìˆ˜\n",
    "    if 'ê³ ê°ìˆ˜(ë°±ë§Œëª…)' in df.columns:\n",
    "        add_missing_flag('ê³ ê°ìˆ˜(ë°±ë§Œëª…)')\n",
    "        features = get_features(['ì„¤ë¦½ì—°ë„', 'ì§ì› ìˆ˜', 'ë¶„ì•¼', 'ì—°ë§¤ì¶œ(ì–µì›)', 'ì´ íˆ¬ìê¸ˆ(ì–µì›)', 'SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)'])\n",
    "        complete = df[df['ê³ ê°ìˆ˜(ë°±ë§Œëª…)'].notnull()]\n",
    "        missing = df[df['ê³ ê°ìˆ˜(ë°±ë§Œëª…)'].isnull()]\n",
    "        if not complete.empty and not missing.empty:\n",
    "            model = GradientBoostingRegressor()\n",
    "            model.fit(complete[features], complete['ê³ ê°ìˆ˜(ë°±ë§Œëª…)'])\n",
    "            df.loc[df['ê³ ê°ìˆ˜(ë°±ë§Œëª…)'].isnull(), 'ê³ ê°ìˆ˜(ë°±ë§Œëª…)'] = model.predict(missing[features])\n",
    "\n",
    "    # 3. ê¸°ì—…ê°€ì¹˜\n",
    "    if 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)' in df.columns:\n",
    "        add_missing_flag('ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)')\n",
    "        features = get_features(['ì„¤ë¦½ì—°ë„', 'ì§ì› ìˆ˜', 'ê³ ê°ìˆ˜(ë°±ë§Œëª…)', 'ë¶„ì•¼', 'ì—°ë§¤ì¶œ(ì–µì›)', 'ì´ íˆ¬ìê¸ˆ(ì–µì›)', 'SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)'])\n",
    "        complete = df[df['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].notnull()]\n",
    "        missing = df[df['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].isnull()]\n",
    "        if not complete.empty and not missing.empty:\n",
    "            model = GradientBoostingRegressor()\n",
    "            model.fit(complete[features], complete['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'])\n",
    "            df.loc[df['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].isnull(), 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] = model.predict(missing[features])\n",
    "\n",
    "    return df\n",
    "\n",
    "# ìµœì¢… ê²°ì¸¡ì¹˜ ë³´ê°„ ì‹œë„\n",
    "train_filled = fill_missing_values_v3(train, is_train=True)\n",
    "train_filled.isnull().sum()  # ëª¨ë“  ê²°ì¸¡ì¹˜ê°€ ì˜ ì±„ì›Œì¡ŒëŠ”ì§€ í™•ì¸\n",
    "\n",
    "test_filled = fill_missing_values_v3(test, is_train=False)\n",
    "test_filled.isnull().sum()  # ëª¨ë“  ê²°ì¸¡ì¹˜ê°€ ì˜ ì±„ì›Œì¡ŒëŠ”ì§€ í™•ì¸\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f74fc1",
   "metadata": {},
   "source": [
    "ì´ìƒì¹˜ ì²˜ë¦¬ ë° íŒŒìƒë³€ìˆ˜ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0505dbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_outliers_train_test(train_df, test_df, num_cols, method='flag+clip'):\n",
    "    train_processed = train_df.copy()\n",
    "    test_processed = test_df.copy()\n",
    "    for col in num_cols:\n",
    "        Q1 = train_df[col].quantile(0.25)\n",
    "        Q3 = train_df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        if 'flag' in method:\n",
    "            train_processed[f'{col}_ì´ìƒì¹˜ì—¬ë¶€'] = ((train_df[col] < lower) | (train_df[col] > upper)).astype(int)\n",
    "            test_processed[f'{col}_ì´ìƒì¹˜ì—¬ë¶€'] = ((test_df[col] < lower) | (test_df[col] > upper)).astype(int)\n",
    "        if 'clip' in method:\n",
    "            train_processed[col] = train_df[col].clip(lower, upper)\n",
    "            test_processed[col] = test_df[col].clip(lower, upper)\n",
    "    return train_processed, test_processed\n",
    "\n",
    "num_cols = train_filled.select_dtypes(include='number').columns.difference(['ì„±ê³µí™•ë¥ ']).tolist()\n",
    "train_processed, test_processed = process_outliers_train_test(train_filled, test_filled, num_cols)\n",
    "\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    df['ì§ì› ìˆ˜_ë¡œê·¸'] = np.log1p(df['ì§ì› ìˆ˜'])\n",
    "    df['ì—°ë§¤ì¶œ_ë¡œê·¸'] = np.log1p(df['ì—°ë§¤ì¶œ(ì–µì›)'])\n",
    "    df['ì´ íˆ¬ìê¸ˆ_ë¡œê·¸'] = np.log1p(df['ì´ íˆ¬ìê¸ˆ(ì–µì›)'])\n",
    "    df['ê³ ê°ìˆ˜_ì§ì›ë¹„'] = df['ê³ ê°ìˆ˜(ë°±ë§Œëª…)'] / (df['ì§ì› ìˆ˜'] + 1)\n",
    "    df['ì—°ë§¤ì¶œ_ì§ì›ë¹„'] = df['ì—°ë§¤ì¶œ(ì–µì›)'] / (df['ì§ì› ìˆ˜'] + 1)\n",
    "    df['íˆ¬ìëŒ€ë¹„ë§¤ì¶œ'] = df['ì—°ë§¤ì¶œ(ì–µì›)'] / (df['ì´ íˆ¬ìê¸ˆ(ì–µì›)'] + 1)\n",
    "    df['SNSë‹¹ê³ ê°'] = df['ê³ ê°ìˆ˜(ë°±ë§Œëª…)'] / (df['SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)'] + 1)\n",
    "    df['ê¸°ì—…ê°€ì¹˜ëŒ€ë¹„íˆ¬ì'] = df['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] / (df['ì´ íˆ¬ìê¸ˆ(ì–µì›)'] + 1)\n",
    "    df['ì„¤ë¦½ë…„ì°¨'] = 2025 - df['ì„¤ë¦½ì—°ë„']\n",
    "    return df\n",
    "\n",
    "X = create_features(train_processed)\n",
    "X_test = create_features(test_processed)\n",
    "y = train_processed['ì„±ê³µí™•ë¥ ']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318f70f9",
   "metadata": {},
   "source": [
    "í”¼ì²˜ ì œê±° + íŒŒìƒë³€ìˆ˜ ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e001935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = [\n",
    "    'ì§ì› ìˆ˜_ê²°ì¸¡_ì´ìƒì¹˜ì—¬ë¶€', 'ê³ ê°ìˆ˜(ë°±ë§Œëª…)_ê²°ì¸¡', 'ê³ ê°ìˆ˜(ë°±ë§Œëª…)_ê²°ì¸¡_ì´ìƒì¹˜ì—¬ë¶€',\n",
    "    'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)_ê²°ì¸¡', 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)_ê²°ì¸¡_ì´ìƒì¹˜ì—¬ë¶€',\n",
    "    'íˆ¬ìë‹¨ê³„_ì´ìƒì¹˜ì—¬ë¶€', 'ë¶„ì•¼_ì´ìƒì¹˜ì—¬ë¶€'\n",
    "]\n",
    "if 'ì„±ê³µí™•ë¥ ' in X.columns:\n",
    "    X = X.drop(columns=['ì„±ê³µí™•ë¥ '])\n",
    "X_reduced = X.drop(columns=[col for col in columns_to_remove if col in X.columns])\n",
    "X_test_reduced = X_test.drop(columns=[col for col in columns_to_remove if col in X_test.columns])\n",
    "X_test_reduced = X_test_reduced[X_reduced.columns]\n",
    "\n",
    "def add_extra_features(df):\n",
    "    df = df.copy()\n",
    "    df['ì´íˆ¬ì_ì§ì›ë¹„'] = df['ì´ íˆ¬ìê¸ˆ(ì–µì›)'] / (df['ì§ì› ìˆ˜_ë¡œê·¸'] + 1)\n",
    "    df['SNSë‹¹ë§¤ì¶œ'] = df['ì—°ë§¤ì¶œ_ë¡œê·¸'] / (df['SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)'] + 1)\n",
    "    #df['ì„¤ë¦½ë…„ì°¨_ì œê³±'] = df['ì„¤ë¦½ë…„ì°¨'] ** 2\n",
    "    df['ê³ ê°ë‹¹ê°€ì¹˜'] = df['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] / (df['ê³ ê°ìˆ˜(ë°±ë§Œëª…)'] + 1)\n",
    "    df['ì—°ë§¤ì¶œ_ê¸°ì—…ê°€ì¹˜ë¹„'] = df['ì—°ë§¤ì¶œ_ë¡œê·¸'] / (df['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] + 1)\n",
    "    # ì„¤ë¦½ë…„ì°¨ * íˆ¬ìë‹¨ê³„\n",
    "    # if 'ì„¤ë¦½ë…„ì°¨' in df.columns and 'íˆ¬ìë‹¨ê³„' in df.columns:\n",
    "    #     df['ì„¤ë¦½Xíˆ¬ìë‹¨ê³„'] = df['ì„¤ë¦½ë…„ì°¨'] * df['íˆ¬ìë‹¨ê³„']\n",
    "    \n",
    "    # ê³ ê°ìˆ˜_ì§ì›ë¹„ * ì—°ë§¤ì¶œ_ì§ì›ë¹„\n",
    "    if 'ê³ ê°ìˆ˜_ì§ì›ë¹„' in df.columns and 'ì—°ë§¤ì¶œ_ì§ì›ë¹„' in df.columns:\n",
    "        df['ê³ ê°Xë§¤ì¶œì§ì›ë¹„'] = df['ê³ ê°ìˆ˜_ì§ì›ë¹„'] * df['ì—°ë§¤ì¶œ_ì§ì›ë¹„']\n",
    "    \n",
    "    # # log(SNS ìˆ˜) + log(ì—°ë§¤ì¶œ)\n",
    "    # if 'SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)' in df.columns and 'ì—°ë§¤ì¶œ(ì–µì›)' in df.columns:\n",
    "    #     df['ë¡œê·¸SNS'] = np.log1p(df['SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)'])\n",
    "    #     df['ë¡œê·¸ë§¤ì¶œ'] = np.log1p(df['ì—°ë§¤ì¶œ(ì–µì›)'])\n",
    "    #     df['ë¡œê·¸SNS+ë§¤ì¶œ'] = df['ë¡œê·¸SNS'] + df['ë¡œê·¸ë§¤ì¶œ']\n",
    "    return df\n",
    "\n",
    "X_enhanced = add_extra_features(X_reduced)\n",
    "X_test_enhanced = add_extra_features(X_test_reduced)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be0c2ec",
   "metadata": {},
   "source": [
    "ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa02c0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "âœ… Fold 1 MAE: 0.19986\n",
      "\n",
      "Fold 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     26\u001b[39m X_val, y_val = X_enhanced.iloc[val_idx], y.iloc[val_idx]\n\u001b[32m     28\u001b[39m model = XGBRegressor(\n\u001b[32m     29\u001b[39m     n_estimators=\u001b[32m500\u001b[39m,\n\u001b[32m     30\u001b[39m     learning_rate=\u001b[32m0.03\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m     n_jobs=-\u001b[32m1\u001b[39m\n\u001b[32m     36\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m y_pred = model.predict(X_val)\n\u001b[32m     40\u001b[39m mae = mean_absolute_error(y_val, y_pred)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\xgboost\\sklearn.py:1247\u001b[39m, in \u001b[36mXGBModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1245\u001b[39m     obj = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1247\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1258\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1259\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1261\u001b[39m \u001b[38;5;28mself\u001b[39m._set_evaluation_result(evals_result)\n\u001b[32m   1262\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\xgboost\\training.py:183\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\xgboost\\core.py:2247\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2243\u001b[39m \u001b[38;5;28mself\u001b[39m._assign_dmatrix_features(dtrain)\n\u001b[32m   2245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2246\u001b[39m     _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2247\u001b[39m         \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2250\u001b[39m     )\n\u001b[32m   2251\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2252\u001b[39m     pred = \u001b[38;5;28mself\u001b[39m.predict(dtrain, output_margin=\u001b[38;5;28;01mTrue\u001b[39;00m, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ì´ì§„í˜• ì¸ì½”ë”©\n",
    "for col in ['ì¸ìˆ˜ì—¬ë¶€', 'ìƒì¥ì—¬ë¶€']:\n",
    "    if col in X_enhanced.columns:\n",
    "        X_enhanced[col] = X_enhanced[col].map({'No': 0, 'Yes': 1})\n",
    "    if col in X_test_enhanced.columns:\n",
    "        X_test_enhanced[col] = X_test_enhanced[col].map({'No': 0, 'Yes': 1})\n",
    "\n",
    "n_repeats = 3\n",
    "n_splits = 5\n",
    "bins = np.linspace(0, 1, 6)\n",
    "y_binned = np.digitize(y, bins)\n",
    "\n",
    "#skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "\n",
    "cv_scores = []\n",
    "test_preds = []\n",
    "\n",
    "# for fold, (train_idx, val_idx) in enumerate(skf.split(X_enhanced, y_binned)):\n",
    "# for fold, (train_idx, val_idx) in enumerate(rkf.split(X_enhanced, y)):\n",
    "for repeat in range(n_repeats):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42 + repeat)\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_enhanced, y_binned)):\n",
    "        print(f\"\\nFold {fold+1}\")\n",
    "        X_tr, y_tr = X_enhanced.iloc[train_idx], y.iloc[train_idx]\n",
    "        X_val, y_val = X_enhanced.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "        model = XGBRegressor(\n",
    "        n_estimators=1325,\n",
    "        learning_rate=0.00375,\n",
    "        max_depth=15,\n",
    "        subsample=0.58315,\n",
    "        colsample_bytree=0.75715,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        print(f\"âœ… Fold {fold+1} MAE: {mae:.5f}\")\n",
    "        cv_scores.append(mae)\n",
    "\n",
    "        test_preds.append(model.predict(X_test_enhanced))\n",
    "\n",
    "print(\"\\nğŸ“‰ í‰ê·  MAE:\", np.mean(cv_scores))\n",
    "\n",
    "final_preds = np.mean(test_preds, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1a3894",
   "metadata": {},
   "source": [
    "ì œì¶œíŒŒì¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f687599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ìµœì¢… ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ\n",
      "<bound method NDFrame.head of              ID      ì„±ê³µí™•ë¥ \n",
      "0     TEST_0000  0.495430\n",
      "1     TEST_0001  0.476088\n",
      "2     TEST_0002  0.423867\n",
      "3     TEST_0003  0.518815\n",
      "4     TEST_0004  0.641490\n",
      "...         ...       ...\n",
      "1750  TEST_1750  0.534823\n",
      "1751  TEST_1751  0.566253\n",
      "1752  TEST_1752  0.487948\n",
      "1753  TEST_1753  0.476240\n",
      "1754  TEST_1754  0.524418\n",
      "\n",
      "[1755 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "sample_submission['ì„±ê³µí™•ë¥ '] = final_preds\n",
    "sample_submission.to_csv('í´ë¦°ì½”ë“œ1ì°¨.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"âœ… ìµœì¢… ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ\")\n",
    "print(sample_submission.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41f988f",
   "metadata": {},
   "source": [
    "í•´ì„1ì°¨ - íê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c970179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_interaction_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # ì„¤ë¦½ë…„ì°¨ * íˆ¬ìë‹¨ê³„\n",
    "    if 'ì„¤ë¦½ë…„ì°¨' in df.columns and 'íˆ¬ìë‹¨ê³„' in df.columns:\n",
    "        df['ì„¤ë¦½Xíˆ¬ìë‹¨ê³„'] = df['ì„¤ë¦½ë…„ì°¨'] * df['íˆ¬ìë‹¨ê³„']\n",
    "    \n",
    "    # ê³ ê°ìˆ˜_ì§ì›ë¹„ * ì—°ë§¤ì¶œ_ì§ì›ë¹„\n",
    "    if 'ê³ ê°ìˆ˜_ì§ì›ë¹„' in df.columns and 'ì—°ë§¤ì¶œ_ì§ì›ë¹„' in df.columns:\n",
    "        df['ê³ ê°Xë§¤ì¶œì§ì›ë¹„'] = df['ê³ ê°ìˆ˜_ì§ì›ë¹„'] * df['ì—°ë§¤ì¶œ_ì§ì›ë¹„']\n",
    "    \n",
    "    # log(SNS ìˆ˜) + log(ì—°ë§¤ì¶œ)\n",
    "    if 'SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)' in df.columns and 'ì—°ë§¤ì¶œ(ì–µì›)' in df.columns:\n",
    "        df['ë¡œê·¸SNS'] = np.log1p(df['SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)'])\n",
    "        df['ë¡œê·¸ë§¤ì¶œ'] = np.log1p(df['ì—°ë§¤ì¶œ(ì–µì›)'])\n",
    "        df['ë¡œê·¸SNS+ë§¤ì¶œ'] = df['ë¡œê·¸SNS'] + df['ë¡œê·¸ë§¤ì¶œ']\n",
    "    \n",
    "    return df\n",
    "\n",
    "X_enhanced = add_interaction_features(X_enhanced)\n",
    "X_test_enhanced = add_interaction_features(X_test_enhanced)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c669b074",
   "metadata": {},
   "source": [
    "íšŒì‚¬ë‘ êµ­ê°€ë³„?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e30c6776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train ê¸°ì¤€ìœ¼ë¡œ êµ­ê°€ë³„ í‰ê·  ì„±ê³µë¥  êµ¬í•˜ê¸°\n",
    "country_success_mean = train_filled.groupby('êµ­ê°€')['ì„±ê³µí™•ë¥ '].mean()\n",
    "\n",
    "# train/test ëª¨ë‘ì— êµ­ê°€ í‰ê·  ì„±ê³µë¥  í”¼ì²˜ë¡œ ì¶”ê°€\n",
    "X_enhanced['êµ­ê°€_ì„±ê³µë¥ í‰ê· '] = X_enhanced['êµ­ê°€'].map(country_success_mean)\n",
    "X_test_enhanced['êµ­ê°€_ì„±ê³µë¥ í‰ê· '] = X_test_enhanced['êµ­ê°€'].map(country_success_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8076df1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "âœ… Fold 1 MAE: 0.19771\n",
      "\n",
      "Fold 2\n",
      "âœ… Fold 2 MAE: 0.19855\n",
      "\n",
      "Fold 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     12\u001b[39m X_val, y_val = X_enhanced.iloc[val_idx], y.iloc[val_idx]\n\u001b[32m     14\u001b[39m model = XGBRegressor(\n\u001b[32m     15\u001b[39m     n_estimators=\u001b[32m500\u001b[39m,\n\u001b[32m     16\u001b[39m     learning_rate=\u001b[32m0.03\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m     n_jobs=-\u001b[32m1\u001b[39m\n\u001b[32m     22\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m y_pred = model.predict(X_val)\n\u001b[32m     26\u001b[39m mae = mean_absolute_error(y_val, y_pred)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\xgboost\\sklearn.py:1247\u001b[39m, in \u001b[36mXGBModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1245\u001b[39m     obj = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1247\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1258\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1259\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1261\u001b[39m \u001b[38;5;28mself\u001b[39m._set_evaluation_result(evals_result)\n\u001b[32m   1262\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\xgboost\\training.py:183\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\xgboost\\core.py:2247\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2243\u001b[39m \u001b[38;5;28mself\u001b[39m._assign_dmatrix_features(dtrain)\n\u001b[32m   2245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2246\u001b[39m     _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2247\u001b[39m         \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2250\u001b[39m     )\n\u001b[32m   2251\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2252\u001b[39m     pred = \u001b[38;5;28mself\u001b[39m.predict(dtrain, output_margin=\u001b[38;5;28;01mTrue\u001b[39;00m, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "bins = np.linspace(0, 1, 6)\n",
    "y_binned = np.digitize(y, bins)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = []\n",
    "test_preds = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_enhanced, y_binned)):\n",
    "    print(f\"\\nFold {fold+1}\")\n",
    "    X_tr, y_tr = X_enhanced.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_val, y_val = X_enhanced.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.03,\n",
    "        max_depth=15,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    model.fit(X_tr, y_tr)\n",
    "    y_pred = model.predict(X_val)\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    print(f\"âœ… Fold {fold+1} MAE: {mae:.5f}\")\n",
    "    cv_scores.append(mae)\n",
    "\n",
    "    test_preds.append(model.predict(X_test_enhanced))\n",
    "\n",
    "print(\"\\nğŸ“‰ í‰ê·  MAE:\", np.mean(cv_scores))\n",
    "\n",
    "final_preds = np.mean(test_preds, axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
