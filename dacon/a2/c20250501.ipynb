{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d541dac",
   "metadata": {},
   "source": [
    "data load, preprocess, import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e22804e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터 로딩\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# ID 제거\n",
    "train.drop(columns=['ID'], inplace=True)\n",
    "test.drop(columns=['ID'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93274781",
   "metadata": {},
   "source": [
    "결측 처리 및 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "104951a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "설립연도              0\n",
       "국가                0\n",
       "분야                0\n",
       "투자단계              0\n",
       "직원 수              0\n",
       "인수여부              0\n",
       "상장여부              0\n",
       "고객수(백만명)          0\n",
       "총 투자금(억원)         0\n",
       "연매출(억원)           0\n",
       "SNS 팔로워 수(백만명)    0\n",
       "기업가치(백억원)         0\n",
       "직원 수_결측           0\n",
       "고객수(백만명)_결측       0\n",
       "기업가치(백억원)_결측      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 기업가치(백억원) 숫자화\n",
    "# 기업가치 컬럼도 범위 문자열 처리 추가\n",
    "\n",
    "def convert_range_to_float(value):\n",
    "    if isinstance(value, str) and '-' in value:\n",
    "        try:\n",
    "            low, high = map(float, value.split('-'))\n",
    "            return (low + high) / 2\n",
    "        except:\n",
    "            return np.nan\n",
    "    try:\n",
    "        return float(value)\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "def encode_categoricals(df, cols):\n",
    "    df = df.copy()\n",
    "    for col in cols:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "    return df\n",
    "\n",
    "def fill_missing_values_v3(df, is_train=True):\n",
    "    df = df.copy()\n",
    "\n",
    "    # 범위 문자열 → 평균 숫자 처리\n",
    "    for col in ['연매출(억원)', '총 투자금(억원)', '기업가치(백억원)']:\n",
    "        df[col] = df[col].apply(convert_range_to_float)\n",
    "\n",
    "    # 분야 결측 및 인코딩\n",
    "    if '분야' in df.columns:\n",
    "        df['분야'] = df['분야'].fillna('Unknown')\n",
    "        df['분야'] = LabelEncoder().fit_transform(df['분야'])\n",
    "\n",
    "    # 국가, 투자단계 인코딩\n",
    "    df = encode_categoricals(df, ['국가', '투자단계'])\n",
    "\n",
    "    # ✅ 결측 플래그 추가 함수\n",
    "    def add_missing_flag(column):\n",
    "        flag_col = f'{column}_결측'\n",
    "        df[flag_col] = df[column].isnull().astype(int)\n",
    "\n",
    "    # ✅ 피처셋 생성 함수\n",
    "    def get_features(base):\n",
    "        return base + (['성공확률'] if is_train else [])\n",
    "\n",
    "    # 1. 직원 수\n",
    "    if '직원 수' in df.columns:\n",
    "        add_missing_flag('직원 수')\n",
    "        features = get_features(['설립연도', '국가', '투자단계', '연매출(억원)', '총 투자금(억원)', 'SNS 팔로워 수(백만명)'])\n",
    "        complete = df[df['직원 수'].notnull()]\n",
    "        missing = df[df['직원 수'].isnull()]\n",
    "        if not complete.empty and not missing.empty:\n",
    "            model = GradientBoostingRegressor()\n",
    "            model.fit(complete[features], complete['직원 수'])\n",
    "            df.loc[df['직원 수'].isnull(), '직원 수'] = model.predict(missing[features])\n",
    "\n",
    "    # 2. 고객 수\n",
    "    if '고객수(백만명)' in df.columns:\n",
    "        add_missing_flag('고객수(백만명)')\n",
    "        features = get_features(['설립연도', '직원 수', '분야', '연매출(억원)', '총 투자금(억원)', 'SNS 팔로워 수(백만명)'])\n",
    "        complete = df[df['고객수(백만명)'].notnull()]\n",
    "        missing = df[df['고객수(백만명)'].isnull()]\n",
    "        if not complete.empty and not missing.empty:\n",
    "            model = GradientBoostingRegressor()\n",
    "            model.fit(complete[features], complete['고객수(백만명)'])\n",
    "            df.loc[df['고객수(백만명)'].isnull(), '고객수(백만명)'] = model.predict(missing[features])\n",
    "\n",
    "    # 3. 기업가치\n",
    "    if '기업가치(백억원)' in df.columns:\n",
    "        add_missing_flag('기업가치(백억원)')\n",
    "        features = get_features(['설립연도', '직원 수', '고객수(백만명)', '분야', '연매출(억원)', '총 투자금(억원)', 'SNS 팔로워 수(백만명)'])\n",
    "        complete = df[df['기업가치(백억원)'].notnull()]\n",
    "        missing = df[df['기업가치(백억원)'].isnull()]\n",
    "        if not complete.empty and not missing.empty:\n",
    "            model = GradientBoostingRegressor()\n",
    "            model.fit(complete[features], complete['기업가치(백억원)'])\n",
    "            df.loc[df['기업가치(백억원)'].isnull(), '기업가치(백억원)'] = model.predict(missing[features])\n",
    "\n",
    "    return df\n",
    "\n",
    "# 최종 결측치 보간 시도\n",
    "train_filled = fill_missing_values_v3(train, is_train=True)\n",
    "train_filled.isnull().sum()  # 모든 결측치가 잘 채워졌는지 확인\n",
    "\n",
    "test_filled = fill_missing_values_v3(test, is_train=False)\n",
    "test_filled.isnull().sum()  # 모든 결측치가 잘 채워졌는지 확인\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f74fc1",
   "metadata": {},
   "source": [
    "이상치 처리 및 파생변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0505dbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_outliers_train_test(train_df, test_df, num_cols, method='flag+clip'):\n",
    "    train_processed = train_df.copy()\n",
    "    test_processed = test_df.copy()\n",
    "    for col in num_cols:\n",
    "        Q1 = train_df[col].quantile(0.25)\n",
    "        Q3 = train_df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        if 'flag' in method:\n",
    "            train_processed[f'{col}_이상치여부'] = ((train_df[col] < lower) | (train_df[col] > upper)).astype(int)\n",
    "            test_processed[f'{col}_이상치여부'] = ((test_df[col] < lower) | (test_df[col] > upper)).astype(int)\n",
    "        if 'clip' in method:\n",
    "            train_processed[col] = train_df[col].clip(lower, upper)\n",
    "            test_processed[col] = test_df[col].clip(lower, upper)\n",
    "    return train_processed, test_processed\n",
    "\n",
    "num_cols = train_filled.select_dtypes(include='number').columns.difference(['성공확률']).tolist()\n",
    "train_processed, test_processed = process_outliers_train_test(train_filled, test_filled, num_cols)\n",
    "\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    df['직원 수_로그'] = np.log1p(df['직원 수'])\n",
    "    df['연매출_로그'] = np.log1p(df['연매출(억원)'])\n",
    "    df['총 투자금_로그'] = np.log1p(df['총 투자금(억원)'])\n",
    "    df['고객수_직원비'] = df['고객수(백만명)'] / (df['직원 수'] + 1)\n",
    "    df['연매출_직원비'] = df['연매출(억원)'] / (df['직원 수'] + 1)\n",
    "    df['투자대비매출'] = df['연매출(억원)'] / (df['총 투자금(억원)'] + 1)\n",
    "    df['SNS당고객'] = df['고객수(백만명)'] / (df['SNS 팔로워 수(백만명)'] + 1)\n",
    "    df['기업가치대비투자'] = df['기업가치(백억원)'] / (df['총 투자금(억원)'] + 1)\n",
    "    df['설립년차'] = 2025 - df['설립연도']\n",
    "    return df\n",
    "\n",
    "X = create_features(train_processed)\n",
    "X_test = create_features(test_processed)\n",
    "y = train_processed['성공확률']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318f70f9",
   "metadata": {},
   "source": [
    "피처 제거 + 파생변수 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e001935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = [\n",
    "    '직원 수_결측_이상치여부', '고객수(백만명)_결측', '고객수(백만명)_결측_이상치여부',\n",
    "    '기업가치(백억원)_결측', '기업가치(백억원)_결측_이상치여부',\n",
    "    '투자단계_이상치여부', '분야_이상치여부'\n",
    "]\n",
    "if '성공확률' in X.columns:\n",
    "    X = X.drop(columns=['성공확률'])\n",
    "X_reduced = X.drop(columns=[col for col in columns_to_remove if col in X.columns])\n",
    "X_test_reduced = X_test.drop(columns=[col for col in columns_to_remove if col in X_test.columns])\n",
    "X_test_reduced = X_test_reduced[X_reduced.columns]\n",
    "\n",
    "def add_extra_features(df):\n",
    "    df = df.copy()\n",
    "    df['총투자_직원비'] = df['총 투자금(억원)'] / (df['직원 수_로그'] + 1)\n",
    "    df['SNS당매출'] = df['연매출_로그'] / (df['SNS 팔로워 수(백만명)'] + 1)\n",
    "    #df['설립년차_제곱'] = df['설립년차'] ** 2\n",
    "    df['고객당가치'] = df['기업가치(백억원)'] / (df['고객수(백만명)'] + 1)\n",
    "    df['연매출_기업가치비'] = df['연매출_로그'] / (df['기업가치(백억원)'] + 1)\n",
    "    # 설립년차 * 투자단계\n",
    "    # if '설립년차' in df.columns and '투자단계' in df.columns:\n",
    "    #     df['설립X투자단계'] = df['설립년차'] * df['투자단계']\n",
    "    \n",
    "    # 고객수_직원비 * 연매출_직원비\n",
    "    if '고객수_직원비' in df.columns and '연매출_직원비' in df.columns:\n",
    "        df['고객X매출직원비'] = df['고객수_직원비'] * df['연매출_직원비']\n",
    "    \n",
    "    # # log(SNS 수) + log(연매출)\n",
    "    # if 'SNS 팔로워 수(백만명)' in df.columns and '연매출(억원)' in df.columns:\n",
    "    #     df['로그SNS'] = np.log1p(df['SNS 팔로워 수(백만명)'])\n",
    "    #     df['로그매출'] = np.log1p(df['연매출(억원)'])\n",
    "    #     df['로그SNS+매출'] = df['로그SNS'] + df['로그매출']\n",
    "    return df\n",
    "\n",
    "X_enhanced = add_extra_features(X_reduced)\n",
    "X_test_enhanced = add_extra_features(X_test_reduced)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be0c2ec",
   "metadata": {},
   "source": [
    "모델 학습 및 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa02c0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "✅ Fold 1 MAE: 0.19986\n",
      "\n",
      "Fold 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     26\u001b[39m X_val, y_val = X_enhanced.iloc[val_idx], y.iloc[val_idx]\n\u001b[32m     28\u001b[39m model = XGBRegressor(\n\u001b[32m     29\u001b[39m     n_estimators=\u001b[32m500\u001b[39m,\n\u001b[32m     30\u001b[39m     learning_rate=\u001b[32m0.03\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m     n_jobs=-\u001b[32m1\u001b[39m\n\u001b[32m     36\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m y_pred = model.predict(X_val)\n\u001b[32m     40\u001b[39m mae = mean_absolute_error(y_val, y_pred)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\xgboost\\sklearn.py:1247\u001b[39m, in \u001b[36mXGBModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1245\u001b[39m     obj = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1247\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1258\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1259\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1261\u001b[39m \u001b[38;5;28mself\u001b[39m._set_evaluation_result(evals_result)\n\u001b[32m   1262\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\xgboost\\training.py:183\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\xgboost\\core.py:2247\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2243\u001b[39m \u001b[38;5;28mself\u001b[39m._assign_dmatrix_features(dtrain)\n\u001b[32m   2245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2246\u001b[39m     _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2247\u001b[39m         \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2250\u001b[39m     )\n\u001b[32m   2251\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2252\u001b[39m     pred = \u001b[38;5;28mself\u001b[39m.predict(dtrain, output_margin=\u001b[38;5;28;01mTrue\u001b[39;00m, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 이진형 인코딩\n",
    "for col in ['인수여부', '상장여부']:\n",
    "    if col in X_enhanced.columns:\n",
    "        X_enhanced[col] = X_enhanced[col].map({'No': 0, 'Yes': 1})\n",
    "    if col in X_test_enhanced.columns:\n",
    "        X_test_enhanced[col] = X_test_enhanced[col].map({'No': 0, 'Yes': 1})\n",
    "\n",
    "n_repeats = 3\n",
    "n_splits = 5\n",
    "bins = np.linspace(0, 1, 6)\n",
    "y_binned = np.digitize(y, bins)\n",
    "\n",
    "#skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "\n",
    "cv_scores = []\n",
    "test_preds = []\n",
    "\n",
    "# for fold, (train_idx, val_idx) in enumerate(skf.split(X_enhanced, y_binned)):\n",
    "# for fold, (train_idx, val_idx) in enumerate(rkf.split(X_enhanced, y)):\n",
    "for repeat in range(n_repeats):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42 + repeat)\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_enhanced, y_binned)):\n",
    "        print(f\"\\nFold {fold+1}\")\n",
    "        X_tr, y_tr = X_enhanced.iloc[train_idx], y.iloc[train_idx]\n",
    "        X_val, y_val = X_enhanced.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "        model = XGBRegressor(\n",
    "        n_estimators=1325,\n",
    "        learning_rate=0.00375,\n",
    "        max_depth=15,\n",
    "        subsample=0.58315,\n",
    "        colsample_bytree=0.75715,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        print(f\"✅ Fold {fold+1} MAE: {mae:.5f}\")\n",
    "        cv_scores.append(mae)\n",
    "\n",
    "        test_preds.append(model.predict(X_test_enhanced))\n",
    "\n",
    "print(\"\\n📉 평균 MAE:\", np.mean(cv_scores))\n",
    "\n",
    "final_preds = np.mean(test_preds, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1a3894",
   "metadata": {},
   "source": [
    "제출파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f687599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 최종 제출 파일 저장 완료\n",
      "<bound method NDFrame.head of              ID      성공확률\n",
      "0     TEST_0000  0.495430\n",
      "1     TEST_0001  0.476088\n",
      "2     TEST_0002  0.423867\n",
      "3     TEST_0003  0.518815\n",
      "4     TEST_0004  0.641490\n",
      "...         ...       ...\n",
      "1750  TEST_1750  0.534823\n",
      "1751  TEST_1751  0.566253\n",
      "1752  TEST_1752  0.487948\n",
      "1753  TEST_1753  0.476240\n",
      "1754  TEST_1754  0.524418\n",
      "\n",
      "[1755 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "sample_submission['성공확률'] = final_preds\n",
    "sample_submission.to_csv('클린코드1차.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"✅ 최종 제출 파일 저장 완료\")\n",
    "print(sample_submission.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41f988f",
   "metadata": {},
   "source": [
    "해석1차 - 폐기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c970179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_interaction_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 설립년차 * 투자단계\n",
    "    if '설립년차' in df.columns and '투자단계' in df.columns:\n",
    "        df['설립X투자단계'] = df['설립년차'] * df['투자단계']\n",
    "    \n",
    "    # 고객수_직원비 * 연매출_직원비\n",
    "    if '고객수_직원비' in df.columns and '연매출_직원비' in df.columns:\n",
    "        df['고객X매출직원비'] = df['고객수_직원비'] * df['연매출_직원비']\n",
    "    \n",
    "    # log(SNS 수) + log(연매출)\n",
    "    if 'SNS 팔로워 수(백만명)' in df.columns and '연매출(억원)' in df.columns:\n",
    "        df['로그SNS'] = np.log1p(df['SNS 팔로워 수(백만명)'])\n",
    "        df['로그매출'] = np.log1p(df['연매출(억원)'])\n",
    "        df['로그SNS+매출'] = df['로그SNS'] + df['로그매출']\n",
    "    \n",
    "    return df\n",
    "\n",
    "X_enhanced = add_interaction_features(X_enhanced)\n",
    "X_test_enhanced = add_interaction_features(X_test_enhanced)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c669b074",
   "metadata": {},
   "source": [
    "회사랑 국가별?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e30c6776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 기준으로 국가별 평균 성공률 구하기\n",
    "country_success_mean = train_filled.groupby('국가')['성공확률'].mean()\n",
    "\n",
    "# train/test 모두에 국가 평균 성공률 피처로 추가\n",
    "X_enhanced['국가_성공률평균'] = X_enhanced['국가'].map(country_success_mean)\n",
    "X_test_enhanced['국가_성공률평균'] = X_test_enhanced['국가'].map(country_success_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8076df1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "✅ Fold 1 MAE: 0.19771\n",
      "\n",
      "Fold 2\n",
      "✅ Fold 2 MAE: 0.19855\n",
      "\n",
      "Fold 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     12\u001b[39m X_val, y_val = X_enhanced.iloc[val_idx], y.iloc[val_idx]\n\u001b[32m     14\u001b[39m model = XGBRegressor(\n\u001b[32m     15\u001b[39m     n_estimators=\u001b[32m500\u001b[39m,\n\u001b[32m     16\u001b[39m     learning_rate=\u001b[32m0.03\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m     n_jobs=-\u001b[32m1\u001b[39m\n\u001b[32m     22\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m y_pred = model.predict(X_val)\n\u001b[32m     26\u001b[39m mae = mean_absolute_error(y_val, y_pred)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\xgboost\\sklearn.py:1247\u001b[39m, in \u001b[36mXGBModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1245\u001b[39m     obj = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1247\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1258\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1259\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1261\u001b[39m \u001b[38;5;28mself\u001b[39m._set_evaluation_result(evals_result)\n\u001b[32m   1262\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\xgboost\\training.py:183\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\xgboost\\core.py:2247\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2243\u001b[39m \u001b[38;5;28mself\u001b[39m._assign_dmatrix_features(dtrain)\n\u001b[32m   2245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2246\u001b[39m     _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2247\u001b[39m         \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2250\u001b[39m     )\n\u001b[32m   2251\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2252\u001b[39m     pred = \u001b[38;5;28mself\u001b[39m.predict(dtrain, output_margin=\u001b[38;5;28;01mTrue\u001b[39;00m, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "bins = np.linspace(0, 1, 6)\n",
    "y_binned = np.digitize(y, bins)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = []\n",
    "test_preds = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_enhanced, y_binned)):\n",
    "    print(f\"\\nFold {fold+1}\")\n",
    "    X_tr, y_tr = X_enhanced.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_val, y_val = X_enhanced.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.03,\n",
    "        max_depth=15,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    model.fit(X_tr, y_tr)\n",
    "    y_pred = model.predict(X_val)\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    print(f\"✅ Fold {fold+1} MAE: {mae:.5f}\")\n",
    "    cv_scores.append(mae)\n",
    "\n",
    "    test_preds.append(model.predict(X_test_enhanced))\n",
    "\n",
    "print(\"\\n📉 평균 MAE:\", np.mean(cv_scores))\n",
    "\n",
    "final_preds = np.mean(test_preds, axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
