데이터 분석을 해서 예측모델을 통해 결과값을 최대한 의미있게 도출하려면
1. 데이터 확인
2. 목표 확인        -Survived 생존 여부 예측
3. 결측치 확인
4. 각 컬럼별 데이터 분석
5. 데이터 라벨링 및 불리언
6. 필요없는 데이터 drop
7. feature engineering
8. 상관계수
9. 모델 선택 (KNN, Decision Tree, Random Forest, GradientBoosting, HistGradientBoosting, Naive Bayes, Support Vecotr Machine ..)
10. 최종 모델 선정
11. 점수 확인 및 대회 평가 지표 ( kaggle : Metric)

여기서 더 추가해야될점이뭐야

--
보완 및 추가할 수 있는 단계
🔁 4. 각 컬럼별 데이터 분석 → 탐색적 데이터 분석 (EDA) 강화
수치형/범주형 변수별 분포 시각화

Survived와의 관계 시각화 (ex. Sex에 따른 생존율, Pclass에 따른 생존율)

Age나 Fare의 outlier(이상치) 탐색 및 처리

시각화 도구 예: seaborn.countplot, sns.violinplot, sns.boxplot

💡 7. Feature Engineering 강화
단순한 파생변수 외에도:

이름(title) 추출 → Mr, Miss, etc.

가족 수(SibSp + Parch + 1) → 단독/동반 여부

Cabin의 알파벳만 추출 → 갑판 정보

티켓 접두어 그룹화

범주형 변수 one-hot encoding 또는 LabelEncoder, OrdinalEncoder 고려

📊 8. 상관계수 외에 모델 기반 중요도 활용
RandomForest, XGBoost, LightGBM 등에서 feature importance 확인

SHAP/Permutation Importance 등 사용 가능

🧪 9-10 사이에 추가: 검증 전략 설정 (Validation Strategy)
교차검증 (KFold, StratifiedKFold)을 써서 모델 안정성 평가

Hold-out 방식과 비교

과적합 방지와 일반화 성능 확인에 중요

🔍 11 직전에 추가: 모델 튜닝 (Hyperparameter Optimization)
GridSearchCV, RandomizedSearchCV, 또는 Optuna 등으로 하이퍼파라미터 튜닝

예: RandomForest(n_estimators, max_depth, min_samples_split) 튜닝

📁 11 후에 추가: 결과 저장 및 재현성 관리
최종 예측값 .csv 저장

랜덤 시드 고정

모델 저장 (joblib, pickle)

커널 공유 시 노트북 마크다운 정리

-----
1. 데이터 확인
2. 목표 확인 - Survived 예측
3. 결측치 확인 및 처리
4. EDA (시각화 포함한 탐색적 분석)
5. 컬럼별 분석 + 이상치 탐색
6. 데이터 라벨링 및 불리언화
7. 필요없는 컬럼 제거
8. Feature Engineering (파생변수 생성)
9. Feature Importance / 상관 분석
10. 검증 전략 설정 (KFold 등)
11. 모델 선택 및 학습
12. 하이퍼파라미터 튜닝
13. 최종 모델 선정
14. 결과 예측 및 저장
15. 평가 지표 확인 및 대회 제출
--
import joblib

# 모델 저장
joblib.dump(best_model, 'final_model.pkl')

# 나중에 불러오기
model = joblib.load('final_model.pkl')

import pickle

# 저장
with open('model.pkl', 'wb') as f:
    pickle.dump(best_model, f)

# 불러오기
with open('model.pkl', 'rb') as f:
    model = pickle.load(f)

항목	이유
전처리 방식 (결측치 처리, 인코딩 등)	같은 방식으로 테스트셋에도 적용해야 함
파생 변수 생성 코드	예측 시 동일 파생 변수 필요
피처 리스트 (사용한 변수들)	모델이 어떤 feature로 학습했는지
하이퍼파라미터 설정	재현을 위해 필수
시드 값 (random_state)	동일 결과 보장을 위해

model = joblib.load('final_model.pkl')

# 2. 저장한 feature 리스트 및 전처리 적용
# 예: 같은 인코딩, 같은 결측치 보간 등

# 3. 예측
X_test = test[feature_list]
preds = model.predict(X_test)
---

왜 시드값이 중요할까?
시드는 랜덤한 과정을 '고정된 결과'로 만들기 위한 값입니다. 타이타닉 같은 비교적 작은 데이터셋에선 이 랜덤 요소가 모델 성능에 더 크게 영향을 미칩니다.

모델 학습 과정에서 랜덤 요소가 생기는 주요 예:

랜덤 요소	설명
데이터 분할 (train_test_split, KFold)	훈련/검증셋 구성 달라짐
모델 내부의 무작위성 (예: RandomForest, XGBoost)	결정트리의 feature 선택, 부트스트랩 등
초기 weight 설정 (신경망 계열)	처음 weight가 다르면 결과도 달라짐
샘플링 (부트스트랩, undersampling 등)	일부 데이터 선택 방식

시드를 고정하지 않으면?
재현 불가능: 똑같은 코드라도 실행할 때마다 결과가 바뀜

모델 선택이 불안정: KFold 성능이 편차를 많이 보이면 어떤 모델이 진짜 좋은 건지 판단하기 어려움

리더보드 점수 불일치: 로컬에서는 점수가 높았는데, 캐글 제출 시 성능이 달라지는 경우 발생 가능

import numpy as np
import random
import os

def seed_everything(seed=42):
    np.random.seed(seed)
    random.seed(seed)
    os.environ["PYTHONHASHSEED"] = str(seed)

    # 모델마다 따로 시드 설정도 필요할 수 있음
    # 예: XGBoost, LightGBM 등도 random_state 파라미터 설정
python
복사
편집
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(random_state=42)

무조건 고정은 기본
random_state=42든 다른 값이든 항상 고정된 시드값으로 실험해야 비교가 가능합니다.

2. 여러 시드로 반복 실험
하나의 시드로 얻은 성능은 운일 수 있어요.

**서로 다른 시드값(예: 5~10개)**로 모델을 반복 학습해보고,

평균 점수

표준편차(불안정도) 를 함께 비교해야 안정성 있는 모델을 고를 수 있습니다.
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
import numpy as np

seeds = [0, 11, 21, 42, 77, 101]
scores = []

for seed in seeds:
    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)
    fold_scores = []
    for train_idx, val_idx in skf.split(X, y):
        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]
        
        model = RandomForestClassifier(random_state=seed)
        model.fit(X_train, y_train)
        preds = model.predict(X_val)
        acc = accuracy_score(y_val, preds)
        fold_scores.append(acc)
    
    print(f"Seed {seed} - Mean CV Score: {np.mean(fold_scores):.4f}")
    scores.append(np.mean(fold_scores))

print(f"All seeds - 평균: {np.mean(scores):.4f}, 표준편차: {np.std(scores):.4f}")

분류	모델 이름	장점 / 특징
🔸선형 모델	Logistic Regression	빠르고 해석 쉬움. baseline으로 좋음
🔸선형 모델	Ridge / Lasso / ElasticNet	정규화 포함 → 과적합 방지에 유리
🔹트리 기반	Decision Tree	매우 직관적. 단독 성능은 약함
🔹트리 기반	ExtraTreesClassifier	RandomForest의 변형. 더 무작위성
🔹트리 기반	CatBoost	범주형 변수 자동 인식. 튜닝 쉬움
🔹트리 기반	HistGradientBoosting	scikit-learn 내장 GBDT. 빠르고 정확
🔹부스팅	AdaBoost	과거에 인기 많았던 Boosting 방식
🔸거리 기반	K-Nearest Neighbors (KNN)	간단하고 직관적. 스케일링 민감
🔸확률 기반	Naive Bayes	단순하지만 텍스트/이산값에 강함
🔸SVM	Support Vector Machine (SVM)	작은 데이터에 강력함. 느릴 수 있음
🔸신경망	MLPClassifier (Multi-layer Perceptron)	기본적인 딥러닝 구조. 작은 데이터에도 적용 가능
🔸앙상블	VotingClassifier / StackingClassifier	여러 모델 결합하여 성능 향상
TabNet: 딥러닝 기반 모델인데 정형데이터에 특화됨 (PyTorch 기반)

AutoML 도구: Auto-sklearn, H2O.ai, TPOT 등 → 다양한 모델 자동 탐색
빠른 베이스라인	Logistic Regression, RandomForest
높은 정확도	LightGBM, XGBoost, CatBoost, Stacking
실험적 성능 향상	TabNet, VotingClassifier, HistGradientBoosting



