{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-tabnet in c:\\users\\human\\.conda\\envs\\dacon\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\human\\.conda\\envs\\dacon\\lib\\site-packages (from pytorch-tabnet) (2.2.5)\n",
      "Requirement already satisfied: scikit_learn>0.21 in c:\\users\\human\\.conda\\envs\\dacon\\lib\\site-packages (from pytorch-tabnet) (1.6.1)\n",
      "Requirement already satisfied: scipy>1.4 in c:\\users\\human\\.conda\\envs\\dacon\\lib\\site-packages (from pytorch-tabnet) (1.15.2)\n",
      "Requirement already satisfied: torch>=1.3 in c:\\users\\human\\.conda\\envs\\dacon\\lib\\site-packages (from pytorch-tabnet) (2.7.0)\n",
      "Requirement already satisfied: tqdm>=4.36 in c:\\users\\human\\.conda\\envs\\dacon\\lib\\site-packages (from pytorch-tabnet) (4.67.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\human\\.conda\\envs\\dacon\\lib\\site-packages (from scikit_learn>0.21->pytorch-tabnet) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\human\\.conda\\envs\\dacon\\lib\\site-packages (from scikit_learn>0.21->pytorch-tabnet) (3.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\human\\.conda\\envs\\dacon\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\human\\.conda\\envs\\dacon\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\human\\.conda\\envs\\dacon\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\human\\.conda\\envs\\dacon\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\human\\.conda\\envs\\dacon\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\human\\.conda\\envs\\dacon\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (2025.3.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\human\\.conda\\envs\\dacon\\lib\\site-packages (from tqdm>=4.36->pytorch-tabnet) (0.4.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\human\\.conda\\envs\\dacon\\lib\\site-packages (from sympy>=1.13.3->torch>=1.3->pytorch-tabnet) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\human\\.conda\\envs\\dacon\\lib\\site-packages (from jinja2->torch>=1.3->pytorch-tabnet) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pytorch-tabnet\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#특성과 타겟 변수 분리\n",
    "train = train.drop(columns=['ID'], axis = 1)\n",
    "test = test.drop(columns=['ID'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     feature  importance\n",
      "4       직원 수    0.318028\n",
      "10  기업가치_클래스    0.141000\n",
      "8     투자대비매출    0.102152\n",
      "1         국가    0.101361\n",
      "9   SNS팔로워구간    0.075463\n",
      "7   고객수(백만명)    0.071945\n",
      "13   고객수대비매출    0.065618\n",
      "0         나이    0.059264\n",
      "12   투자금대비매출    0.021470\n",
      "2       분야점수    0.014619\n",
      "11   직원수대비매출    0.013443\n",
      "6       상장여부    0.008346\n",
      "3       투자단계    0.004768\n",
      "5       인수여부    0.002525\n",
      "분야\n",
      "핀테크     0.567151\n",
      "0       0.552042\n",
      "기술      0.540103\n",
      "물류      0.539939\n",
      "에듀테크    0.539011\n",
      "AI      0.537079\n",
      "푸드테크    0.533731\n",
      "게임      0.532869\n",
      "에너지     0.529545\n",
      "이커머스    0.520482\n",
      "헬스케어    0.493671\n",
      "Name: 성공확률, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 1. 설립연도 → 나이 변환\n",
    "CURRENT_YEAR = 2025\n",
    "train['나이'] = CURRENT_YEAR - train['설립연도']\n",
    "test['나이'] = CURRENT_YEAR - test['설립연도']\n",
    "\n",
    "# 2. 국가 Encoding\n",
    "le_country = LabelEncoder()\n",
    "train['국가'] = le_country.fit_transform(train['국가'].fillna('Missing'))\n",
    "test['국가'] = le_country.transform(test['국가'].fillna('Missing'))\n",
    "\n",
    "# 3. 분야 점수화\n",
    "분야_점수 = {\n",
    "    '핀테크': 8,\n",
    "    0: 8,               # NaN 처리된 0\n",
    "    '기술': 8,\n",
    "    '물류': 7,\n",
    "    '에듀테크': 7,\n",
    "    'AI': 7,\n",
    "    '푸드테크': 7,\n",
    "    '게임': 6,\n",
    "    '에너지': 6,\n",
    "    '이커머스': 6,\n",
    "    '헬스케어': 6\n",
    "}\n",
    "\n",
    "# 분야 점수 맵핑\n",
    "train['분야점수'] = train['분야'].map(분야_점수)\n",
    "test['분야점수'] = test['분야'].map(분야_점수)\n",
    "\n",
    "# 혹시 NaN 있으면 0으로\n",
    "train['분야점수'] = train['분야점수'].fillna(0)\n",
    "test['분야점수'] = test['분야점수'].fillna(0)\n",
    "\n",
    "# 4. 투자단계 수치화\n",
    "stage_mapping = {'Seed': 0, 'Series A': 1, 'Series B': 2, 'Series C': 3, 'IPO': 4}\n",
    "train['투자단계'] = train['투자단계'].map(stage_mapping).fillna(0)\n",
    "test['투자단계'] = test['투자단계'].map(stage_mapping).fillna(0)\n",
    "\n",
    "# 5. 인수/상장 여부 0/1 매핑\n",
    "bool_map = {'Yes': 1, 'No': 0}\n",
    "for feature in ['인수여부', '상장여부']:\n",
    "    train[feature] = train[feature].map(bool_map).fillna(0)\n",
    "    test[feature] = test[feature].map(bool_map).fillna(0)\n",
    "\n",
    "# 6. 투자대비매출 Feature 추가\n",
    "train['투자대비매출'] = train['연매출(억원)'].fillna(0) / (train['총 투자금(억원)'].fillna(0) + 1)\n",
    "test['투자대비매출'] = test['연매출(억원)'].fillna(0) / (test['총 투자금(억원)'].fillna(0) + 1)\n",
    "\n",
    "# 7. SNS 팔로워 수 구간화\n",
    "def sns_bin(x):\n",
    "    if x < 1:\n",
    "        return 0\n",
    "    elif x < 3:\n",
    "        return 1\n",
    "    elif x < 5:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "train['SNS팔로워구간'] = train['SNS 팔로워 수(백만명)'].apply(lambda x: sns_bin(x) if not pd.isna(x) else 0)\n",
    "test['SNS팔로워구간'] = test['SNS 팔로워 수(백만명)'].apply(lambda x: sns_bin(x) if not pd.isna(x) else 0)\n",
    "\n",
    "# 8. 기업가치 수치화\n",
    "def parse_value(x):\n",
    "    if pd.isnull(x):\n",
    "        return 0\n",
    "    elif '6000' in str(x):\n",
    "        return 6\n",
    "    elif '4500' in str(x):\n",
    "        return 5\n",
    "    elif '3500' in str(x):\n",
    "        return 4\n",
    "    elif '2500' in str(x):\n",
    "        return 3\n",
    "    elif '1500' in str(x):\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "train['기업가치_클래스'] = train['기업가치(백억원)'].apply(parse_value)\n",
    "test['기업가치_클래스'] = test['기업가치(백억원)'].apply(parse_value)\n",
    "\n",
    "train['직원수대비매출'] = train['연매출(억원)'] / (train['직원 수'] + 1)\n",
    "test['직원수대비매출'] = test['연매출(억원)'] / (test['직원 수'] + 1)\n",
    "\n",
    "train['투자금대비매출'] = train['연매출(억원)'] / (train['총 투자금(억원)'] + 1)\n",
    "test['투자금대비매출'] = test['연매출(억원)'] / (test['총 투자금(억원)'] + 1)\n",
    "\n",
    "train['고객수대비매출'] = train['연매출(억원)'] / (train['고객수(백만명)'] + 1)\n",
    "test['고객수대비매출'] = test['연매출(억원)'] / (test['고객수(백만명)'] + 1)\n",
    "\n",
    "\n",
    "# 9. 결측치는 모두 0으로 대체\n",
    "train = train.fillna(0)\n",
    "test = test.fillna(0)\n",
    "\n",
    "# 10. 최종 feature 리스트\n",
    "features = [\n",
    "    '나이', '국가', '분야점수', '투자단계', '직원 수',\n",
    "    '인수여부', '상장여부', '고객수(백만명)', '투자대비매출',\n",
    "    'SNS팔로워구간', '기업가치_클래스', '직원수대비매출', '투자금대비매출', '고객수대비매출'\n",
    "]\n",
    "\n",
    "# 11. TabNet용 cat_idxs, cat_dims 설정\n",
    "category_features = ['국가', '분야점수', '투자단계', 'SNS팔로워구간', '기업가치_클래스']\n",
    "cat_idxs = [features.index(col) for col in category_features]\n",
    "cat_dims = [int(train[col].max()) + 2 for col in category_features]\n",
    "\n",
    "\n",
    "models = []  # 모델 저장할 리스트\n",
    "\n",
    "# 학습용 코드 (간단 버전)\n",
    "model = TabNetRegressor(\n",
    "    cat_idxs=cat_idxs,\n",
    "    cat_dims=cat_dims,\n",
    "    seed=42222,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train=train[features].values,\n",
    "    y_train=train['성공확률'].values.reshape(-1, 1),\n",
    "    max_epochs=50,\n",
    "    patience=10,\n",
    "    batch_size=512,\n",
    "    virtual_batch_size=128,\n",
    "    eval_metric=['mae']\n",
    ")\n",
    "models.append(model) \n",
    "# 예를 들어 모델 하나 (fold 0번 모델)로 해볼게\n",
    "model = models[0]\n",
    "\n",
    "# 1. Feature Importance 가져오기\n",
    "feature_importance = model.feature_importances_\n",
    "\n",
    "# 2. Feature 이름과 importance 매칭\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': feature_importance\n",
    "})\n",
    "\n",
    "# 3. 중요도 기준 내림차순 정렬\n",
    "importance_df = importance_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# 4. 결과 출력\n",
    "print(importance_df)\n",
    "\n",
    "분야별_성공률 = train.groupby('분야')['성공확률'].mean().sort_values(ascending=False)\n",
    "print(분야별_성공률)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 Fold 1/5\n",
      "▶ Pretraining...\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_unsup_loss_numpy = 10107287.0\n",
      "▶ Fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "c:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_mae = 0.22078\n",
      "\n",
      "🔁 Fold 2/5\n",
      "▶ Pretraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_unsup_loss_numpy = 1155383689216.0\n",
      "▶ Fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "c:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 56 with best_epoch = 46 and best_val_0_mae = 0.20788\n",
      "\n",
      "🔁 Fold 3/5\n",
      "▶ Pretraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 43 and best_val_0_unsup_loss_numpy = 3255687.5\n",
      "▶ Fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "c:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_mae = 0.20303\n",
      "\n",
      "🔁 Fold 4/5\n",
      "▶ Pretraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_unsup_loss_numpy = 1876983808000.0\n",
      "▶ Fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "c:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 57 with best_epoch = 47 and best_val_0_mae = 0.20281\n",
      "\n",
      "🔁 Fold 5/5\n",
      "▶ Pretraining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_unsup_loss_numpy = -40.24195861816406\n",
      "▶ Fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "c:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 27 and best_val_0_mae = 0.20727\n",
      "\n",
      "✅ 모든 fold 모델 학습 완료!\n",
      "CV Scores (MAE): [0.22077590191064905, 0.20787698324748446, 0.2030319442340306, 0.20280840533801486, 0.20726974452563696]\n",
      "Mean CV Score (MAE): 0.20835259585116317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\dacon\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "# 1. 타겟 지정\n",
    "target = train['성공확률']  \n",
    "X = train[features]\n",
    "y = target\n",
    "\n",
    "# 2. KFold 설정\n",
    "N_FOLDS = 5\n",
    "kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "models = [] # 모델 저장 리스트\n",
    "cv_scores = []\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(X)):\n",
    "    print(f\"\\n🔁 Fold {fold+1}/{N_FOLDS}\")\n",
    "    \n",
    "    X_train = X.iloc[train_idx].values   # 무조건 .values 붙여\n",
    "    y_train = y.iloc[train_idx].values.reshape(-1, 1)\n",
    "\n",
    "    X_valid = X.iloc[valid_idx].values   # 무조건 .values 붙여\n",
    "    y_valid = y.iloc[valid_idx].values.reshape(-1, 1)\n",
    "    \n",
    "    # for i, idx in enumerate(cat_idxs):\n",
    "    #     col_values = X_train[:, idx]\n",
    "    #     max_val = col_values.max()\n",
    "    #     expected_dim = cat_dims[i]\n",
    "    #     print(f\"Feature {features[idx]}: max value={max_val}, expected dim={expected_dim}\")\n",
    "\n",
    "    # 3. 비지도 사전학습 (Pretraining)\n",
    "    print(\"▶ Pretraining...\")\n",
    "    pretrainer = TabNetPretrainer(\n",
    "        cat_idxs=cat_idxs,\n",
    "        cat_dims=cat_dims,\n",
    "        seed=42 + fold,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    pretrainer.fit(\n",
    "        X_train=X_train,\n",
    "        eval_set=[X_valid],\n",
    "        max_epochs=100,\n",
    "        batch_size=512,\n",
    "        virtual_batch_size=64,\n",
    "        patience=10\n",
    "    )\n",
    "    \n",
    "    # 4. 지도 Fine-tuning\n",
    "    print(\"▶ Fine-tuning...\")\n",
    "    model = TabNetRegressor(\n",
    "        cat_idxs=cat_idxs,\n",
    "        cat_dims=cat_dims,\n",
    "        seed=42 + fold,\n",
    "        verbose=0,\n",
    "        optimizer_fn=torch.optim.AdamW\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train=X_train, y_train=y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        from_unsupervised=pretrainer,\n",
    "        eval_metric=['mae'],\n",
    "        max_epochs=100,\n",
    "        patience=10\n",
    "    )\n",
    "\n",
    "    # 5. 모델 저장\n",
    "    models.append(model)\n",
    "    cv_scores.append(model.best_cost)\n",
    "\n",
    "print(\"\\n✅ 모든 fold 모델 학습 완료!\")\n",
    "print(\"CV Scores (MAE):\", cv_scores)\n",
    "print(\"Mean CV Score (MAE):\", np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict with fold 1\n"
     ]
    }
   ],
   "source": [
    "# 저장된 모델들로 예측\n",
    "predictions_list = []\n",
    "\n",
    "for fold, model in enumerate(models):\n",
    "    print(f\"Predict with fold {fold+1}\")\n",
    "    preds = model.predict(test[features].values)\n",
    "    predictions_list.append(preds)\n",
    "\n",
    "# 평균 예측\n",
    "final_predictions = np.mean(predictions_list, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['성공확률'] = final_predictions\n",
    "sample_submission.to_csv('./baseline_submission.csv', index = False, encoding = 'utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
