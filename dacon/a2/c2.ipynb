{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03add211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ì„¤ë¦½ì—°ë„', 'êµ­ê°€', 'ë¶„ì•¼', 'íˆ¬ìë‹¨ê³„', 'ì§ì› ìˆ˜', 'ê³ ê°ìˆ˜(ë°±ë§Œëª…)', 'ì´ íˆ¬ìê¸ˆ(ì–µì›)', 'ì—°ë§¤ì¶œ(ì–µì›)', 'SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)', 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)', 'ì„±ê³µí™•ë¥ ', 'ì§ì› ìˆ˜_ê²°ì¸¡', 'ê³ ê°ìˆ˜(ë°±ë§Œëª…)_ê²°ì¸¡', 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)_ê²°ì¸¡']\n",
      "â–¶ ì—°ë§¤ì¶œ(ì–µì›)_ì´ìƒì¹˜ì—¬ë¶€ - ì´ìƒì¹˜ ê°œìˆ˜(train): 0\n",
      "â–¶ ê³ ê°ìˆ˜(ë°±ë§Œëª…)_ì´ìƒì¹˜ì—¬ë¶€ - ì´ìƒì¹˜ ê°œìˆ˜(train): 0\n",
      "â–¶ SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)_ì´ìƒì¹˜ì—¬ë¶€ - ì´ìƒì¹˜ ê°œìˆ˜(train): 0\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“¦ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”©\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# âœ… í•œê¸€ ì„¤ì • ë° ë§ˆì´ë„ˆìŠ¤ ê¹¨ì§ ë°©ì§€\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# ğŸ“‚ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "train = pd.read_csv('train.csv').drop(columns=['ID'])\n",
    "test = pd.read_csv('test.csv').drop(columns=['ID'])\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# ğŸ”§ ë²”ìœ„ê°’ ì²˜ë¦¬ í•¨ìˆ˜\n",
    "def convert_range_to_float(value):\n",
    "    if isinstance(value, str) and '-' in value:\n",
    "        try:\n",
    "            low, high = map(float, value.split('-'))\n",
    "            return (low + high) / 2\n",
    "        except:\n",
    "            return np.nan\n",
    "    try:\n",
    "        return float(value)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# ğŸ”§ ë²”ì£¼í˜• ì¸ì½”ë”©\n",
    "def encode_categoricals(df, cols):\n",
    "    df = df.copy()\n",
    "    for col in cols:\n",
    "        df[col] = LabelEncoder().fit_transform(df[col].astype(str))\n",
    "    return df\n",
    "\n",
    "# ğŸ”§ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ í•¨ìˆ˜\n",
    "def fill_missing_values(df, is_train=True):\n",
    "    df = df.copy()\n",
    "\n",
    "    # ë²”ìœ„ ë¬¸ìì—´ â†’ í‰ê·  ìˆ«ì ì²˜ë¦¬\n",
    "    for col in ['ì—°ë§¤ì¶œ(ì–µì›)', 'ì´ íˆ¬ìê¸ˆ(ì–µì›)', 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)']:\n",
    "        df[col] = df[col].apply(convert_range_to_float)\n",
    "\n",
    "    # ë¶„ì•¼ ê²°ì¸¡ ë° ì¸ì½”ë”©\n",
    "    if 'ë¶„ì•¼' in df.columns:\n",
    "        df['ë¶„ì•¼'] = df['ë¶„ì•¼'].fillna('Unknown')\n",
    "        df['ë¶„ì•¼'] = LabelEncoder().fit_transform(df['ë¶„ì•¼'])\n",
    "\n",
    "    # êµ­ê°€, íˆ¬ìë‹¨ê³„ ì¸ì½”ë”©\n",
    "    df = encode_categoricals(df, ['êµ­ê°€', 'íˆ¬ìë‹¨ê³„'])\n",
    "\n",
    "    # âœ… ê²°ì¸¡ í”Œë˜ê·¸ ì¶”ê°€ í•¨ìˆ˜\n",
    "    def add_missing_flag(column):\n",
    "        flag_col = f'{column}_ê²°ì¸¡'\n",
    "        df[flag_col] = df[column].isnull().astype(int)\n",
    "\n",
    "    # âœ… í”¼ì²˜ì…‹ ìƒì„± í•¨ìˆ˜\n",
    "    def get_features(base):\n",
    "        return base + (['ì„±ê³µí™•ë¥ '] if is_train else [])\n",
    "\n",
    "    # 1. ì§ì› ìˆ˜\n",
    "    if 'ì§ì› ìˆ˜' in df.columns:\n",
    "        add_missing_flag('ì§ì› ìˆ˜')\n",
    "        features = get_features(['ì„¤ë¦½ì—°ë„', 'êµ­ê°€', 'íˆ¬ìë‹¨ê³„', 'ì—°ë§¤ì¶œ(ì–µì›)', 'ì´ íˆ¬ìê¸ˆ(ì–µì›)', 'SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)'])\n",
    "        complete = df[df['ì§ì› ìˆ˜'].notnull()]\n",
    "        missing = df[df['ì§ì› ìˆ˜'].isnull()]\n",
    "        if not complete.empty and not missing.empty:\n",
    "            model = GradientBoostingRegressor()\n",
    "            model.fit(complete[features], complete['ì§ì› ìˆ˜'])\n",
    "            df.loc[df['ì§ì› ìˆ˜'].isnull(), 'ì§ì› ìˆ˜'] = model.predict(missing[features])\n",
    "\n",
    "    # 2. ê³ ê° ìˆ˜\n",
    "    if 'ê³ ê°ìˆ˜(ë°±ë§Œëª…)' in df.columns:\n",
    "        add_missing_flag('ê³ ê°ìˆ˜(ë°±ë§Œëª…)')\n",
    "        features = get_features(['ì„¤ë¦½ì—°ë„', 'ì§ì› ìˆ˜', 'ë¶„ì•¼', 'ì—°ë§¤ì¶œ(ì–µì›)', 'ì´ íˆ¬ìê¸ˆ(ì–µì›)', 'SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)'])\n",
    "        complete = df[df['ê³ ê°ìˆ˜(ë°±ë§Œëª…)'].notnull()]\n",
    "        missing = df[df['ê³ ê°ìˆ˜(ë°±ë§Œëª…)'].isnull()]\n",
    "        if not complete.empty and not missing.empty:\n",
    "            model = GradientBoostingRegressor()\n",
    "            model.fit(complete[features], complete['ê³ ê°ìˆ˜(ë°±ë§Œëª…)'])\n",
    "            df.loc[df['ê³ ê°ìˆ˜(ë°±ë§Œëª…)'].isnull(), 'ê³ ê°ìˆ˜(ë°±ë§Œëª…)'] = model.predict(missing[features])\n",
    "\n",
    "    # 3. ê¸°ì—…ê°€ì¹˜\n",
    "    if 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)' in df.columns:\n",
    "        add_missing_flag('ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)')\n",
    "        features = get_features(['ì„¤ë¦½ì—°ë„', 'ì§ì› ìˆ˜', 'ê³ ê°ìˆ˜(ë°±ë§Œëª…)', 'ë¶„ì•¼', 'ì—°ë§¤ì¶œ(ì–µì›)', 'ì´ íˆ¬ìê¸ˆ(ì–µì›)', 'SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)'])\n",
    "        complete = df[df['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].notnull()]\n",
    "        missing = df[df['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].isnull()]\n",
    "        if not complete.empty and not missing.empty:\n",
    "            model = GradientBoostingRegressor()\n",
    "            model.fit(complete[features], complete['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'])\n",
    "            df.loc[df['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'].isnull(), 'ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] = model.predict(missing[features])\n",
    "\n",
    "    return df\n",
    "\n",
    "# ğŸ“Œ ë°ì´í„° ì „ì²˜ë¦¬\n",
    "train_filled = fill_missing_values(train, is_train=True)\n",
    "test_filled = fill_missing_values(test, is_train=False)\n",
    "\n",
    "# ğŸ“Œ ì´ìƒì¹˜ ì²˜ë¦¬ í•¨ìˆ˜\n",
    "def process_outliers(train_df, test_df, num_cols, method='flag+clip'):\n",
    "    train, test = train_df.copy(), test_df.copy()\n",
    "    for col in num_cols:\n",
    "        Q1, Q3 = train[col].quantile([0.25, 0.75])\n",
    "        IQR = Q3 - Q1\n",
    "        lower, upper = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n",
    "\n",
    "        if 'flag' in method:\n",
    "            train[f'{col}_ì´ìƒì¹˜ì—¬ë¶€'] = ((train[col] < lower) | (train[col] > upper)).astype(int)\n",
    "            test[f'{col}_ì´ìƒì¹˜ì—¬ë¶€'] = ((test[col] < lower) | (test[col] > upper)).astype(int)\n",
    "\n",
    "        if 'clip' in method:\n",
    "            train[col] = train[col].clip(lower, upper)\n",
    "            test[col] = test[col].clip(lower, upper)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "num_cols = train_filled.select_dtypes(include=np.number).columns.drop('ì„±ê³µí™•ë¥ ').tolist()\n",
    "train_processed, test_processed = process_outliers(train_filled, test_filled, num_cols)\n",
    "\n",
    "\n",
    "\n",
    "def detect_outliers_summary(df, columns):\n",
    "    summary = []\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "        summary.append({\n",
    "            'ì»¬ëŸ¼ëª…': col,\n",
    "            'ì´ìƒì¹˜ ìˆ˜': len(outliers),\n",
    "            'ì „ì²´ ëŒ€ë¹„ ë¹„ìœ¨(%)': round(len(outliers) / len(df) * 100, 2)\n",
    "        })\n",
    "    return pd.DataFrame(summary).sort_values(by='ì´ìƒì¹˜ ìˆ˜', ascending=False)\n",
    "\n",
    "# log ë³€í™˜ (0ë³´ë‹¤ í° ê°’ë§Œ ë³€í™˜, log1pëŠ” log(1+x))\n",
    "num_cols = train_filled.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "print(num_cols)\n",
    "log_train = train_filled[num_cols].copy()\n",
    "for col in num_cols:\n",
    "    if (log_train[col] > 0).all():  # ìŒìˆ˜, 0 ìˆëŠ” ì»¬ëŸ¼ì€ ì œì™¸\n",
    "        log_train[col] = np.log1p(log_train[col])\n",
    "\n",
    "def process_outliers_train_test(train_df, test_df, num_cols, method='flag+clip'):\n",
    "    \"\"\"\n",
    "    train ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ IQR ì´ìƒì¹˜ íƒì§€ ê¸°ì¤€ì„ ì¡ê³ ,\n",
    "    train/test ëª¨ë‘ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì´ìƒì¹˜ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    train_processed = train_df.copy()\n",
    "    test_processed = test_df.copy()\n",
    "    outlier_bounds = {}\n",
    "\n",
    "    for col in num_cols:\n",
    "        Q1 = train_df[col].quantile(0.25)\n",
    "        Q3 = train_df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        outlier_bounds[col] = (lower, upper)\n",
    "\n",
    "        # ì´ìƒì¹˜ í”Œë˜ê·¸\n",
    "        if 'flag' in method:\n",
    "            train_processed[f'{col}_ì´ìƒì¹˜ì—¬ë¶€'] = ((train_df[col] < lower) | (train_df[col] > upper)).astype(int)\n",
    "            test_processed[f'{col}_ì´ìƒì¹˜ì—¬ë¶€'] = ((test_df[col] < lower) | (test_df[col] > upper)).astype(int)\n",
    "\n",
    "        # í´ë¦¬í•‘\n",
    "        if 'clip' in method:\n",
    "            train_processed[col] = train_df[col].clip(lower, upper)\n",
    "            test_processed[col] = test_df[col].clip(lower, upper)\n",
    "\n",
    "        # ë¡œê·¸ ë³€í™˜\n",
    "        if 'log' in method:\n",
    "            if (train_processed[col] >= 0).all() and (test_processed[col] >= 0).all():\n",
    "                train_processed[col] = np.log1p(train_processed[col])\n",
    "                test_processed[col] = np.log1p(test_processed[col])\n",
    "            else:\n",
    "                print(f\"[ê²½ê³ ] {col}ì€ log1p ë¶ˆê°€ëŠ¥ (ìŒìˆ˜ ë˜ëŠ” 0 í¬í•¨)\")\n",
    "\n",
    "    return train_processed, test_processed, outlier_bounds\n",
    "\n",
    "# 'ì„±ê³µí™•ë¥ 'ì€ trainì—ë§Œ ìˆìœ¼ë¯€ë¡œ ì œì™¸\n",
    "num_cols = train_filled.select_dtypes(include=np.number).columns.tolist()\n",
    "num_cols = [col for col in num_cols if col != 'ì„±ê³µí™•ë¥ ']\n",
    "\n",
    "# ì´ìƒì¹˜ ì²˜ë¦¬ ìˆ˜í–‰\n",
    "train_processed, test_processed, bounds = process_outliers_train_test(train_filled, test_filled, num_cols, method='flag+clip')\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸: ì¼ë¶€ ì»¬ëŸ¼ì— ëŒ€í•´ ì´ìƒì¹˜ ì—¬ë¶€ í”Œë˜ê·¸ ë¶„í¬ ì¶œë ¥\n",
    "for col in ['ì—°ë§¤ì¶œ(ì–µì›)', 'ê³ ê°ìˆ˜(ë°±ë§Œëª…)', 'SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)']:\n",
    "    flag_col = f'{col}_ì´ìƒì¹˜ì—¬ë¶€'\n",
    "    if flag_col in train_processed.columns:\n",
    "        print(f\"â–¶ {flag_col} - ì´ìƒì¹˜ ê°œìˆ˜(train): {train_processed[flag_col].sum()}\")\n",
    "\n",
    "# ğŸ“Œ íŒŒìƒë³€ìˆ˜ ìƒì„±\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    df['ì§ì› ìˆ˜_ë¡œê·¸'] = np.log1p(df['ì§ì› ìˆ˜'])\n",
    "    df['ì—°ë§¤ì¶œ_ë¡œê·¸'] = np.log1p(df['ì—°ë§¤ì¶œ(ì–µì›)'])\n",
    "    df['ì´ íˆ¬ìê¸ˆ_ë¡œê·¸'] = np.log1p(df['ì´ íˆ¬ìê¸ˆ(ì–µì›)'])\n",
    "    df['ê³ ê°ìˆ˜_ì§ì›ë¹„'] = df['ê³ ê°ìˆ˜(ë°±ë§Œëª…)'] / (df['ì§ì› ìˆ˜'] + 1)\n",
    "    df['ì—°ë§¤ì¶œ_ì§ì›ë¹„'] = df['ì—°ë§¤ì¶œ(ì–µì›)'] / (df['ì§ì› ìˆ˜'] + 1)\n",
    "    df['íˆ¬ìëŒ€ë¹„ë§¤ì¶œ'] = df['ì—°ë§¤ì¶œ(ì–µì›)'] / (df['ì´ íˆ¬ìê¸ˆ(ì–µì›)'] + 1)\n",
    "    df['SNSë‹¹ê³ ê°'] = df['ê³ ê°ìˆ˜(ë°±ë§Œëª…)'] / (df['SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)'] + 1)\n",
    "    df['ê¸°ì—…ê°€ì¹˜ëŒ€ë¹„íˆ¬ì'] = df['ê¸°ì—…ê°€ì¹˜(ë°±ì–µì›)'] / (df['ì´ íˆ¬ìê¸ˆ(ì–µì›)'] + 1)\n",
    "    df['ì„¤ë¦½ë…„ì°¨'] = 2025 - df['ì„¤ë¦½ì—°ë„']\n",
    "    df['ì„¤ë¦½Xë‹¨ê³„'] = df['ì„¤ë¦½ë…„ì°¨'] * df['íˆ¬ìë‹¨ê³„']\n",
    "    df['ë§¤ì¶œXê³ ê°ë¹„'] = df['ì—°ë§¤ì¶œ_ì§ì›ë¹„'] * df['ê³ ê°ìˆ˜_ì§ì›ë¹„']\n",
    "    df['SNSë§¤ì¶œí•©'] = np.log1p(df['SNS íŒ”ë¡œì›Œ ìˆ˜(ë°±ë§Œëª…)'] + df['ì—°ë§¤ì¶œ(ì–µì›)'])\n",
    "    ë‹¨ê³„ë³„_í‰ê· íˆ¬ì = df.groupby('íˆ¬ìë‹¨ê³„')['ì´ íˆ¬ìê¸ˆ(ì–µì›)'].transform('mean')\n",
    "    df['íˆ¬ì_í‰ê· ë¹„'] = df['ì´ íˆ¬ìê¸ˆ(ì–µì›)'] / (ë‹¨ê³„ë³„_í‰ê· íˆ¬ì + 1)\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "X = train_processed.copy()  # â† ì—¬ê¸°ì„œ train_processedì— ì´ìƒì¹˜ í”Œë˜ê·¸ê°€ ë“¤ì–´ìˆì–´ì•¼ í•¨\n",
    "X = create_features(X)      # íŒŒìƒë³€ìˆ˜ ì¶”ê°€\n",
    "X_test = test_processed.copy()\n",
    "X_test = create_features(X_test)\n",
    "y = train_processed['ì„±ê³µí™•ë¥ ']  # ë˜ëŠ” ë¯¸ë¦¬ ë¶„ë¦¬í•œ y ì‚¬ìš©\n",
    "\n",
    "# ğŸ“Œ í•„ìš”ì—†ëŠ” ì»¬ëŸ¼ ì œê±°\n",
    "remove_cols = ['ì§ì› ìˆ˜', 'ì—°ë§¤ì¶œ(ì–µì›)', 'ì„¤ë¦½ì—°ë„', 'ì´ íˆ¬ìê¸ˆ(ì–µì›)', 'ì§ì› ìˆ˜_ê²°ì¸¡', 'ê³ ê°ìˆ˜_ê²°ì¸¡']\n",
    "X.drop(columns=[col for col in remove_cols if col in X.columns], inplace=True)\n",
    "X_test.drop(columns=[col for col in remove_cols if col in X_test.columns], inplace=True)\n",
    "\n",
    "# âœ… ì´ì§„í˜• ì¸ì½”ë”©\n",
    "for col in ['ì¸ìˆ˜ì—¬ë¶€', 'ìƒì¥ì—¬ë¶€']:\n",
    "    for df in [X, X_test]:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].map({'No': 0, 'Yes': 1})\n",
    "\n",
    "# 'ì„±ê³µí™•ë¥ ' ì»¬ëŸ¼ì´ ìˆë‹¤ë©´ ì‚­ì œ\n",
    "if 'ì„±ê³µí™•ë¥ ' in X.columns:\n",
    "    X = X.drop(columns=['ì„±ê³µí™•ë¥ '])\n",
    "\n",
    "# y ê²°í•©\n",
    "X_with_y = X.join(y.rename(\"ì„±ê³µí™•ë¥ \"))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fd84dc",
   "metadata": {},
   "source": [
    "ë¶„í¬ë„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78fced1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "save_dir ='ê°dataset_ë¶„í¬ë„'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë§Œ ëŒ€ìƒìœ¼ë¡œ ì§„í–‰\n",
    "numeric_cols = train.select_dtypes(include='number').columns.tolist()\n",
    "if 'ì„±ê³µí™•ë¥ ' in numeric_cols:\n",
    "    numeric_cols.remove('ì„±ê³µí™•ë¥ ')  # íƒ€ê²Ÿ ë³€ìˆ˜ ì œì™¸\n",
    "\n",
    "for col in numeric_cols:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    \n",
    "    # KDE plot (ë°€ë„ ì¶”ì • ë¶„í¬)\n",
    "    sns.kdeplot(train[col], label='Train', fill=True, color='skyblue')\n",
    "    sns.kdeplot(test[col], label='Test', fill=True, color='salmon')\n",
    "    \n",
    "    plt.title(f\"[{col}] - Train vs Test ë¶„í¬ ë¹„êµ\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # íŒŒì¼ ì €ì¥\n",
    "    save_path = os.path.join(save_dir, f\"{col}_distribution.png\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "# ë²”ì£¼í˜• ì»¬ëŸ¼ ìë™ ì¶”ì¶œ\n",
    "categorical_cols = train.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "for col in categorical_cols:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "\n",
    "    # ê° ë°ì´í„°ì…‹ì˜ ë¶„í¬ ì •ê·œí™” í›„ ë°ì´í„°í”„ë ˆì„í™”\n",
    "    train_counts = train[col].value_counts(normalize=True).rename('Train')\n",
    "    test_counts = test[col].value_counts(normalize=True).rename('Test')\n",
    "    \n",
    "    combined = pd.concat([train_counts, test_counts], axis=1).fillna(0)\n",
    "\n",
    "    combined.plot(kind='bar', color=['skyblue', 'salmon'])\n",
    "    plt.title(f\"[{col}] - ë²”ì£¼ë³„ ë¹„ìœ¨ (Train vs Test)\")\n",
    "    plt.ylabel(\"ë¹„ìœ¨\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # íŒŒì¼ ì €ì¥\n",
    "    save_path = os.path.join(save_dir, f\"{col}_ë²”ì£¼í˜•_ë¹„êµ.png\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
