import mysql.connector
from config import MYSQL_HOST, MYSQL_PORT, MYSQL_USER, MYSQL_PASSWORD, MYSQL_DB

import pandas as pd
from mecab import MeCab
from gensim.models import Word2Vec
import re
import os
import jpype


# 1. DB ì—°ê²°
def get_connection():
    return mysql.connector.connect(
        host=MYSQL_HOST,
        port=MYSQL_PORT,
        user=MYSQL_USER,
        password=MYSQL_PASSWORD,
        database=MYSQL_DB
    )

# 2. ëŒ“ê¸€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
def load_comments():
    conn = get_connection()
    query = "SELECT comment FROM comments WHERE comment IS NOT NULL"
    df = pd.read_sql(query, conn)
    conn.close()
    return df

# 3. ì „ì²˜ë¦¬ í•¨ìˆ˜
def clean_and_tokenize(comments):
    mecab = MeCab()
    tokenized_comments = []

    for comment in comments:
        # í•œê¸€, ìˆ«ì, ê³µë°±ë§Œ ë‚¨ê¸°ê³  ì •ì œ
        comment = re.sub(r"[^ã„±-ã…ã…-ã…£ê°€-í£0-9\s]", "", str(comment))
        # í˜•íƒœì†Œ ë¶„ì„ + ëª…ì‚¬/í˜•ìš©ì‚¬/ë™ì‚¬ ì¶”ì¶œ
        tokens = mecab.pos(comment)
        words = [word for word, pos in tokens if pos in ["NNG", "VV", "VA"] and len(word) > 1]
        if words:
            tokenized_comments.append(words)

    return tokenized_comments

# 4. Word2Vec ëª¨ë¸ í•™ìŠµ ë° ì €ì¥
def train_word2vec(sentences):
    model = Word2Vec(
        sentences,
       vector_size=200,   # ë²¡í„° ì°¨ì› ëŠ˜ë¦¼
        window=10,         # ë¬¸ë§¥ ë²”ìœ„ ëŠ˜ë¦¼
        min_count=5,       # ìµœì†Œ ë“±ì¥ ë¹ˆë„ ëŠ˜ë¦¼
        workers=4,         # ë©€í‹°ì½”ì–´ ì²˜ë¦¬
        sg=1,              # Skip-gram ë°©ì‹
        epochs=30          # ì—í­ìˆ˜ ëŠ˜ë¦¼
    )
    os.makedirs("models", exist_ok=True)
    model.save("models/word2vec.model")
    print("âœ… Word2Vec ëª¨ë¸ ì €ì¥ ì™„ë£Œ")

# 5. ì „ì²´ ì‹¤í–‰ íë¦„
if __name__ == "__main__":
    df = load_comments()
    sentences = clean_and_tokenize(df["comment"].tolist())
    print(f"ğŸ“„ ì´ {len(sentences)}ê°œì˜ ë¬¸ì¥ í•™ìŠµ ì¤€ë¹„ ì™„ë£Œ")
    train_word2vec(sentences)


