1. flask기반 웹사이트작업 (word2vec 홈페이지처럼)
2. flask와 연동된 python 파일작업 ( 데이터전처리, 함수, api키연동.. 코드분리화해서 각각 파일작업 및 git에올릴땐 config제외 )
3. 크롤링에서 나온 결과물을 mysql 로컬DB에 저장 후 이거랑 연동
4. db에서 결과물들을 불러와서 이를 model.wv.most_.. 에 대입 및 적절한 언어모델 분석
5. 결과물 main홈페이지 출력

1. Flask 기초 웹 디비 연동  -   v
2. 유튜브 api키 받기        -   v
3. 강사님 코드 리뷰         -   v
4. 크롤링작업               -   v
5. DB save load 확인        -  v  
6. 전처리 + 형태소 분석     -
7. Word2Vec 학습            -

MySQL DB ─▶ DataFrame ─▶ 텍스트 정제/토큰화 ─▶ Word2Vec 훈련 ─▶ 모델 저장 / 검색
2.
YouTube 댓글 크롤링에는 Google Cloud의 "YouTube Data API v3" 사용이 필요


3.

크롤링 작업 구간 따로 / flask 작업 구간 따로 -o
모델 학습은 미리하고 저장 ( .model파일)
웹에서는 모델만 불러와서 결과만 추출 - most_similar()

train_model.py      ← 오프라인에서 학습하고 Word2Vec 저장 (.model)
       │
       ▼
model/word2vec.model ← 모델 파일
       │
       ▼
app.py (웹 요청)
 → load_model() → model.wv.most_similar(keyword)
 → 결과 응답

 from gensim.models import Word2Vec

# 서버 시작 시 모델 한 번만 불러오기
model = Word2Vec.load("model/word2vec.model")

def get_similar_words(keyword):
    try:
        result = model.wv.most_similar(keyword, topn=10)
        return [w for w, _ in result]
    except KeyError:
        return ["❗ 학습된 단어가 아닙니다."]

from flask import Flask, render_template, request, jsonify
from word2vec_fast import get_similar_words  # 위 함수를 따로 분리했다면

@app.route('/analyze', methods=['POST'])
def analyze():
    keyword = request.json.get('keyword')
    similar_words = get_similar_words(keyword)
    return jsonify({'similar': similar_words})


1. 단어를 "의미 기반 벡터"로 바꿈
단어들을 다차원 벡터(보통 100~300차원)로 바꾸고

비슷한 맥락에서 쓰인 단어끼리 벡터 공간에서 가까운 위치에 배치함.


요약: Word2Vec이 할 수 있는 것 / 없는 것
할 수 있는 것 ✅	못하는 것 ❌
비슷한 맥락의 단어 추정	논리적 추론 (예: "강릉은 강원도의 뭐다")
간단한 벡터 연산 (서울 - 한국 + 일본 ≈ 도쿄)	긴 체인 연산 (교토, 상하이 같이 들어가면 오류)
유사 단어 검색 (유사도 기반)	문맥에 따른 단어 의미 구분 (동음이의어 처리 어려움)
간단한 감성 연산 (칭찬 - 욕설 ≈ 긍정 감성)	사실 관계, 숫자 추론, 순서 등

연산은 2~3개 단어까지만 조합하는 게 좋음

더 정밀한 의미 분리 → FastText, BERT, KoBERT, ELECTRA, Sentence-BERT로 넘어가야 함

감성/주제별 클러스터링은 Word2Vec 후에 추가로 ML 알고리즘 적용해야 정확함


Word2Vec이 할 수 있는 것 (✅)
비슷한 맥락의 단어 추정: 예를 들어, T1의 "블루"와 "레드" 또는 "경기", "선수"와 같은 유사한 단어들을 찾는 데는 유용할 수 있습니다.

간단한 벡터 연산: 특정 단어들을 뺀 후 다른 단어를 더하는 방식으로, 예를 들어 "T1"과 "승리"의 관계를 추정하는 것 같은 작업이 가능합니다.

유사 단어 검색: "T1", "팀", "경기"와 비슷한 단어를 찾는 데 효과적입니다.

Word2Vec이 할 수 없는 것 (❌)
논리적 추론: 예를 들어, "강릉은 강원도의 뭐다"와 같은 관계를 처리하는 것은 Word2Vec에서는 어려워요. 이처럼 특정 지역 또는 팀 간의 복잡한 관계를 추론하는 데는 부족할 수 있습니다.

긴 체인 연산: 예를 들어, T1 경기 중 "선수 X는 승리 후 MVP" 이런 형태에서, 선수의 승리 상태와 MVP를 연결하여 맥락을 분석하는 것은 어렵습니다.

동음이의어 처리: 예를 들어, "블루"가 "블루팀"을 의미하는지, 아니면 "블루" 아이템을 의미하는지를 Word2Vec으로 정확히 구분하기 힘들 수 있습니다.

사실 관계나 순서 추론: T1의 경기 흐름과 같은 시간적인 맥락을 Word2Vec은 정확하게 반영하기 어렵습니다.

Word2Vec은 T1의 경기 데이터와 같은 복잡한 상황을 처리하기에는 다소 제한적일 수 있습니다. 하지만 비슷한 맥락의 단어나 단어 간 유사도를 추정하는 데는 유용하고, 텍스트 내에서 반복적으로 등장하는 패턴을 분석하려면 충분히 활용 가능할 수 있습니다.

하지만 복잡한 문맥 분석, 논리적 추론, 시간적 흐름을 고려한 분석을 하려면 Word2Vec만으로는 한계가 있을 수 있으므로, BERT나 GPT와 같은 더 복잡한 언어 모델을 활용하는 것이 더 적합할 수 있습니다.

Word2Vec을 기반으로 먼저 단어 벡터를 추출하고, 그 후에 더 고도화된 모델을 사용해서 복잡한 문맥을 분석하는 접근이 좋을 것 같아요.


 시각화 기능을 붙이고 싶다면?
scikit-learn의 PCA 또는 TSNE를 사용해 벡터 차원을 2D로 줄이고

matplotlib이나 plotly를 사용해 시각적으로 단어 분포를 보여줄 수 있어요

유사 단어를 점으로 표시하고, 마우스 오버하면 단어 이름이 나오도록 하면 word2vec.kr과 유사한 느낌이 납니다

✳️ 다음 스텝 추천
위 구조 기반으로 Flask 웹앱 구성

시각화 기능 추가 (원한다면 예시도 드릴 수 있어요)

페이커, T1, 우승, 젠지, LCK 같은 단어 클러스터링

나중엔 "페이커가 우승한 상황"처럼 자연어도 받아서 벡터로 바꾸는 기능도 넣을 수 있어요. 그땐 KoBERT 같은 문장 임베딩 모델과 결합하면 됩니다.
LCK
T1 

선수

댓글 크롤링 - 감성 
-> 

< 모델 >
    <gensim.model> - 아키텍쳐
        gpt모델 
    [ --- ]