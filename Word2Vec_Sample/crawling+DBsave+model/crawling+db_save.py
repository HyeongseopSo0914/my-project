from crawler import collect_all
from db import get_connection
import pandas as pd

# ì„¤ì •
CHANNEL_ID = "UCw1DsweY9b2AKGjV4kGJP1A"  # LCK ê³µì‹ ì±„ë„
CSV_PATH = "lck_comments.csv"           # íŒŒì¼ëª…ë„ T1 â†’ LCKë¡œ ë³€ê²½

# 1. ëŒ“ê¸€ ìˆ˜ì§‘ ë° CSV ì €ì¥
def crawl_and_save_csv():
    print("ğŸ“¥ ìœ íŠœë¸Œ ëŒ“ê¸€ ìˆ˜ì§‘ ì¤‘...")
    df = collect_all(CHANNEL_ID)  # query ì œê±°ë¨
    if df.empty:
        print("âŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    df.to_csv(CSV_PATH, index=False, encoding="utf-8-sig")
    print(f"âœ… CSV ì €ì¥ ì™„ë£Œ â†’ {CSV_PATH}")
    return df

# 2. DBì— ì €ì¥
def save_df_to_db(df):
    print("ğŸ—ƒï¸  DB ì €ì¥ ì¤‘...")
    conn = get_connection()
    cursor = conn.cursor()

    insert_query = """
    INSERT INTO comments (video_id, comment)
    VALUES (%s, %s)
    """

    for _, row in df.iterrows():
        cursor.execute(insert_query, (row['video_id'], row['comment']))

    conn.commit()
    cursor.close()
    conn.close()
    print("âœ… DB ì €ì¥ ì™„ë£Œ")

# ì‹¤í–‰
if __name__ == "__main__":
    df = crawl_and_save_csv()
    if df is not None:
        save_df_to_db(df)
